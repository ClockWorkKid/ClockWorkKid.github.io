{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import setup_seed\n",
    "from dataset import Kitti, get_dataloader\n",
    "from model import PointPillars\n",
    "from loss import Loss\n",
    "from tensorboardX import SummaryWriter\n",
    "import cv2\n",
    "import io\n",
    "\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import setup_seed, keep_bbox_from_image_range, \\\n",
    "    keep_bbox_from_lidar_range, write_pickle, write_label, \\\n",
    "    iou2d, iou3d_camera, iou_bev\n",
    "from dataset import Kitti, get_dataloader\n",
    "from model import PointPillars\n",
    "from loss import Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the scalars and convert the plot to a tensor image\n",
    "def plot_scalars(scalars, step):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(scalars)\n",
    "    ax.set_title(f'Step {step}')\n",
    "    ax.set_xlabel('Scalar Index')\n",
    "    ax.set_ylabel('Value')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Convert the plot to a PNG image\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Convert PNG buffer to a tensor image\n",
    "    image = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)  # Decode the image\n",
    "    image = torch.from_numpy(image).permute(2, 0, 1)#.unsqueeze(0)  # Convert to PyTorch tensor and add batch dimension\n",
    "    return image\n",
    "\n",
    "def save_summary(writer, loss_dict, global_step, tag, gating_prob, lr=None, momentum=None, model=None, data=None, flag=False):\n",
    "    for k, v in loss_dict.items():\n",
    "        writer.add_scalar(f'{tag}/{k}', v, global_step)\n",
    "    if lr is not None:\n",
    "        writer.add_scalar('lr', lr, global_step)\n",
    "    if momentum is not None:\n",
    "        writer.add_scalar('momentum', momentum, global_step)\n",
    "    if model is not None and global_step % 1000 == 0:\n",
    "        for tag, value in model.named_parameters():\n",
    "            # import pdb\n",
    "            # pdb.set_trace()\n",
    "            if value.grad is not None:\n",
    "                writer.add_histogram(tag + \"/grad\", value.grad.cpu(), global_step)\n",
    "    \n",
    "    if global_step % 100 == 0:\n",
    "        image = plot_scalars(gating_prob.detach().cpu().numpy(), global_step)\n",
    "        writer.add_image(\"Scalars Plot\", image, global_step=global_step)\n",
    "    # for i in data:\n",
    "    #     del i['gt_names']\n",
    "    #     del i['image_info']\n",
    "    #     del i['calib_info']\n",
    "    #     del i['difficulty']\n",
    "\n",
    "    # writer.add_graph(model, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.data_root = \"dataset/KITTI\"\n",
    "        self.saved_path = \"logs/pillar_sequence_mem_lin_gat_9_param_share_test\"\n",
    "        self.saved_path_exact = self.saved_path + \"/results_exact\"\n",
    "        self.saved_path_estimate = self.saved_path + \"/results_estimate\"\n",
    "        self.batch_size = 4\n",
    "        self.num_workers = 4\n",
    "        self.window_length = 1\n",
    "        self.nclasses = 3\n",
    "        self.init_lr = 0.00025\n",
    "        self.max_epoch = 200\n",
    "        self.log_freq = 1        \n",
    "        self.ckpt_freq_epoch = 1\n",
    "        self.val_freq_epoch = 1\n",
    "        self.no_cuda = not torch.cuda.is_available()\n",
    " \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Kitti(data_root=args.data_root,\n",
    "                        split='train')\n",
    "val_dataset = Kitti(data_root=args.data_root,\n",
    "                    split='val')\n",
    "train_dataloader = get_dataloader(dataset=train_dataset, \n",
    "                                    batch_size=args.batch_size, \n",
    "                                    num_workers=args.num_workers,\n",
    "                                    shuffle=True)\n",
    "val_dataloader = get_dataloader(dataset=val_dataset, \n",
    "                                batch_size=args.batch_size, \n",
    "                                num_workers=args.num_workers,\n",
    "                                shuffle=False)\n",
    "\n",
    "# data = train_dataset.__getitem__(9)\n",
    "\n",
    "train_dataset_length = len(train_dataset.sorted_ids)\n",
    "train_dataset_batch_count =  train_dataset_length \n",
    "val_dataset_length = len(val_dataset.sorted_ids)\n",
    "\n",
    "def get_sequence_from_velodyne_path(file_path):\n",
    "    parts = file_path.split('/')\n",
    "    file_name = parts[-1]\n",
    "    extracted_part = file_name.split('_')[0]\n",
    "    return extracted_part\n",
    "\n",
    "# Print the extracted part\n",
    "\n",
    "CLASSES = Kitti.CLASSES\n",
    "LABEL2CLASSES = {v:k for k, v in CLASSES.items()}\n",
    "\n",
    "\n",
    "pcd_limit_range = np.array([0, -40, -3, 70.4, 40, 0.0], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Loss, Optimizer, Scheduler, Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.no_cuda:\n",
    "    pointpillars = PointPillars(nclasses=args.nclasses).cuda()\n",
    "else:\n",
    "    pointpillars = PointPillars(nclasses=args.nclasses)\n",
    "\n",
    "model_flag = False\n",
    "\n",
    "loss_func = Loss()\n",
    "\n",
    "max_iters = 2* train_dataset_batch_count * args.max_epoch\n",
    "init_lr = args.init_lr\n",
    "optimizer = torch.optim.AdamW(params=pointpillars.parameters(), \n",
    "                                lr=init_lr, \n",
    "                                betas=(0.95, 0.99),\n",
    "                                weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,  \n",
    "                                                max_lr=init_lr*10, \n",
    "                                                total_steps=max_iters, \n",
    "                                                pct_start=0.4, \n",
    "                                                anneal_strategy='cos',\n",
    "                                                cycle_momentum=True, \n",
    "                                                base_momentum=0.95*0.895, \n",
    "                                                max_momentum=0.95,\n",
    "                                                div_factor=10)\n",
    "\n",
    "\n",
    "saved_logs_path = os.path.join(args.saved_path, 'summary')\n",
    "import shutil\n",
    "if os.path.exists(saved_logs_path):\n",
    "    shutil.rmtree(saved_logs_path)\n",
    "os.makedirs(saved_logs_path, exist_ok=True)\n",
    "writer = SummaryWriter(saved_logs_path)\n",
    "saved_ckpt_path = os.path.join(args.saved_path, 'checkpoints')\n",
    "os.makedirs(saved_ckpt_path, exist_ok=True)\n",
    "\n",
    "# Directory for exact results\n",
    "saved_path_exact = args.saved_path_exact\n",
    "os.makedirs(saved_path_exact, exist_ok=True)\n",
    "saved_submit_path_exact = os.path.join(saved_path_exact, 'submit')\n",
    "os.makedirs(saved_submit_path_exact, exist_ok=True)\n",
    "\n",
    "# Directory for estimate results\n",
    "saved_path_estimate = args.saved_path_estimate\n",
    "os.makedirs(saved_path_estimate, exist_ok=True)\n",
    "saved_submit_path_estimate = os.path.join(saved_path_estimate, 'submit')\n",
    "os.makedirs(saved_submit_path_estimate, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_thresholds(tp_scores, total_num_valid_gt, num_sample_pts=41):\n",
    "    score_thresholds = []\n",
    "    tp_scores = sorted(tp_scores)[::-1]\n",
    "    cur_recall, pts_ind = 0, 0\n",
    "    for i, score in enumerate(tp_scores):\n",
    "        lrecall = (i + 1) / total_num_valid_gt\n",
    "        rrecall = (i + 2) / total_num_valid_gt\n",
    "\n",
    "        if i == len(tp_scores) - 1:\n",
    "            score_thresholds.append(score)\n",
    "            break\n",
    "\n",
    "        if (lrecall + rrecall) / 2 < cur_recall:\n",
    "            continue\n",
    "\n",
    "        score_thresholds.append(score)\n",
    "        pts_ind += 1\n",
    "        cur_recall = pts_ind / (num_sample_pts - 1)\n",
    "    return score_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_eval(det_results, gt_results, CLASSES, saved_path):\n",
    "    '''\n",
    "    det_results: list,\n",
    "    gt_results: dict(id -> det_results)\n",
    "    CLASSES: dict\n",
    "    '''\n",
    "    assert len(det_results) == len(gt_results)\n",
    "    f = open(os.path.join(saved_path, 'eval_results.txt'), 'w')\n",
    "\n",
    "    # 1. calculate iou\n",
    "    ious = {\n",
    "        'bbox_2d': [],\n",
    "        'bbox_bev': [],\n",
    "        'bbox_3d': []\n",
    "    }\n",
    "    ids = list(sorted(gt_results.keys()))\n",
    "    for id in ids:\n",
    "        gt_result = gt_results[id]['annos']\n",
    "        det_result = det_results[id]\n",
    "\n",
    "        # 1.1, 2d bboxes iou\n",
    "        gt_bboxes2d = gt_result['bbox'].astype(np.float32)\n",
    "        det_bboxes2d = det_result['bbox'].astype(np.float32)\n",
    "        iou2d_v = iou2d(torch.from_numpy(gt_bboxes2d).cuda(), torch.from_numpy(det_bboxes2d).cuda())\n",
    "        ious['bbox_2d'].append(iou2d_v.cpu().numpy())\n",
    "\n",
    "        # 1.2, bev iou\n",
    "        gt_location = gt_result['location'].astype(np.float32)\n",
    "        gt_dimensions = gt_result['dimensions'].astype(np.float32)\n",
    "        gt_rotation_y = gt_result['rotation_y'].astype(np.float32)\n",
    "        det_location = det_result['location'].astype(np.float32)\n",
    "        det_dimensions = det_result['dimensions'].astype(np.float32)\n",
    "        det_rotation_y = det_result['rotation_y'].astype(np.float32)\n",
    "\n",
    "        gt_bev = np.concatenate([gt_location[:, [0, 2]], gt_dimensions[:, [0, 2]], gt_rotation_y[:, None]], axis=-1)\n",
    "        det_bev = np.concatenate([det_location[:, [0, 2]], det_dimensions[:, [0, 2]], det_rotation_y[:, None]], axis=-1)\n",
    "        iou_bev_v = iou_bev(torch.from_numpy(gt_bev).cuda(), torch.from_numpy(det_bev).cuda())\n",
    "        ious['bbox_bev'].append(iou_bev_v.cpu().numpy())\n",
    "\n",
    "        # 1.3, 3dbboxes iou\n",
    "        gt_bboxes3d = np.concatenate([gt_location, gt_dimensions, gt_rotation_y[:, None]], axis=-1)\n",
    "        det_bboxes3d = np.concatenate([det_location, det_dimensions, det_rotation_y[:, None]], axis=-1)\n",
    "        iou3d_v = iou3d_camera(torch.from_numpy(gt_bboxes3d).cuda(), torch.from_numpy(det_bboxes3d).cuda())\n",
    "        ious['bbox_3d'].append(iou3d_v.cpu().numpy())\n",
    "\n",
    "    MIN_IOUS = {\n",
    "        'Pedestrian': [0.5, 0.5, 0.5],\n",
    "        'Cyclist': [0.5, 0.5, 0.5],\n",
    "        'Car': [0.7, 0.7, 0.7]\n",
    "    }\n",
    "    MIN_HEIGHT = [40, 25, 25]\n",
    "\n",
    "    overall_results = {}\n",
    "    for e_ind, eval_type in enumerate(['bbox_2d', 'bbox_bev', 'bbox_3d']):\n",
    "        eval_ious = ious[eval_type]\n",
    "        eval_ap_results, eval_aos_results = {}, {}\n",
    "        for cls in CLASSES:\n",
    "            eval_ap_results[cls] = []\n",
    "            eval_aos_results[cls] = []\n",
    "            CLS_MIN_IOU = MIN_IOUS[cls][e_ind]\n",
    "            for difficulty in [0, 1, 2]:\n",
    "                # 1. bbox property\n",
    "                total_gt_ignores, total_det_ignores, total_dc_bboxes, total_scores = [], [], [], []\n",
    "                total_gt_alpha, total_det_alpha = [], []\n",
    "                for id in ids:\n",
    "                    gt_result = gt_results[id]['annos']\n",
    "                    det_result = det_results[id]\n",
    "\n",
    "                    # 1.1 gt bbox property\n",
    "                    cur_gt_names = gt_result['name']\n",
    "                    cur_difficulty = gt_result['difficulty']\n",
    "                    gt_ignores, dc_bboxes = [], []\n",
    "                    for j, cur_gt_name in enumerate(cur_gt_names):\n",
    "                        ignore = cur_difficulty[j] < 0 or cur_difficulty[j] > difficulty\n",
    "                        if cur_gt_name == cls:\n",
    "                            valid_class = 1\n",
    "                        elif cls == 'Pedestrian' and cur_gt_name == 'Person_sitting':\n",
    "                            valid_class = 0\n",
    "                        elif cls == 'Car' and cur_gt_name == 'Van':\n",
    "                            valid_class = 0\n",
    "                        else:\n",
    "                            valid_class = -1\n",
    "                        \n",
    "                        if valid_class == 1 and not ignore:\n",
    "                            gt_ignores.append(0)\n",
    "                        elif valid_class == 0 or (valid_class == 1 and ignore):\n",
    "                            gt_ignores.append(1)\n",
    "                        else:\n",
    "                            gt_ignores.append(-1)\n",
    "                        \n",
    "                        if cur_gt_name == 'DontCare':\n",
    "                            dc_bboxes.append(gt_result['bbox'][j])\n",
    "                    total_gt_ignores.append(gt_ignores)\n",
    "                    total_dc_bboxes.append(np.array(dc_bboxes))\n",
    "                    total_gt_alpha.append(gt_result['alpha'])\n",
    "\n",
    "                    # 1.2 det bbox property\n",
    "                    cur_det_names = det_result['name']\n",
    "                    cur_det_heights = det_result['bbox'][:, 3] - det_result['bbox'][:, 1]\n",
    "                    det_ignores = []\n",
    "                    for j, cur_det_name in enumerate(cur_det_names):\n",
    "                        if cur_det_heights[j] < MIN_HEIGHT[difficulty]:\n",
    "                            det_ignores.append(1)\n",
    "                        elif cur_det_name == cls:\n",
    "                            det_ignores.append(0)\n",
    "                        else:\n",
    "                            det_ignores.append(-1)\n",
    "                    total_det_ignores.append(det_ignores)\n",
    "                    total_scores.append(det_result['score'])\n",
    "                    total_det_alpha.append(det_result['alpha'])\n",
    "\n",
    "                # 2. calculate scores thresholds for PR curve\n",
    "                tp_scores = []\n",
    "                for i, id in enumerate(ids):\n",
    "                    cur_eval_ious = eval_ious[i]\n",
    "                    gt_ignores, det_ignores = total_gt_ignores[i], total_det_ignores[i]\n",
    "                    scores = total_scores[i]\n",
    "\n",
    "                    nn, mm = cur_eval_ious.shape\n",
    "                    assigned = np.zeros((mm, ), dtype=np.bool_)\n",
    "                    for j in range(nn):\n",
    "                        if gt_ignores[j] == -1:\n",
    "                            continue\n",
    "                        match_id, match_score = -1, -1\n",
    "                        for k in range(mm):\n",
    "                            if not assigned[k] and det_ignores[k] >= 0 and cur_eval_ious[j, k] > CLS_MIN_IOU and scores[k] > match_score:\n",
    "                                match_id = k\n",
    "                                match_score = scores[k]\n",
    "                        if match_id != -1:\n",
    "                            assigned[match_id] = True\n",
    "                            if det_ignores[match_id] == 0 and gt_ignores[j] == 0:\n",
    "                                tp_scores.append(match_score)\n",
    "                total_num_valid_gt = np.sum([np.sum(np.array(gt_ignores) == 0) for gt_ignores in total_gt_ignores])\n",
    "                score_thresholds = get_score_thresholds(tp_scores, total_num_valid_gt)    \n",
    "            \n",
    "                # 3. draw PR curve and calculate mAP\n",
    "                tps, fns, fps, total_aos = [], [], [], []\n",
    "\n",
    "                for score_threshold in score_thresholds:\n",
    "                    tp, fn, fp = 0, 0, 0\n",
    "                    aos = 0\n",
    "                    for i, id in enumerate(ids):\n",
    "                        cur_eval_ious = eval_ious[i]\n",
    "                        gt_ignores, det_ignores = total_gt_ignores[i], total_det_ignores[i]\n",
    "                        gt_alpha, det_alpha = total_gt_alpha[i], total_det_alpha[i]\n",
    "                        scores = total_scores[i]\n",
    "\n",
    "                        nn, mm = cur_eval_ious.shape\n",
    "                        assigned = np.zeros((mm, ), dtype=np.bool_)\n",
    "                        for j in range(nn):\n",
    "                            if gt_ignores[j] == -1:\n",
    "                                continue\n",
    "                            match_id, match_iou = -1, -1\n",
    "                            for k in range(mm):\n",
    "                                if not assigned[k] and det_ignores[k] >= 0 and scores[k] >= score_threshold and cur_eval_ious[j, k] > CLS_MIN_IOU:\n",
    "    \n",
    "                                    if det_ignores[k] == 0 and cur_eval_ious[j, k] > match_iou:\n",
    "                                        match_iou = cur_eval_ious[j, k]\n",
    "                                        match_id = k\n",
    "                                    elif det_ignores[k] == 1 and match_iou == -1:\n",
    "                                        match_id = k\n",
    "\n",
    "                            if match_id != -1:\n",
    "                                assigned[match_id] = True\n",
    "                                if det_ignores[match_id] == 0 and gt_ignores[j] == 0:\n",
    "                                    tp += 1\n",
    "                                    if eval_type == 'bbox_2d':\n",
    "                                        aos += (1 + np.cos(gt_alpha[j] - det_alpha[match_id])) / 2\n",
    "                            else:\n",
    "                                if gt_ignores[j] == 0:\n",
    "                                    fn += 1\n",
    "                            \n",
    "                        for k in range(mm):\n",
    "                            if det_ignores[k] == 0 and scores[k] >= score_threshold and not assigned[k]:\n",
    "                                fp += 1\n",
    "                        \n",
    "                        # In case 2d bbox evaluation, we should consider dontcare bboxes\n",
    "                        if eval_type == 'bbox_2d':\n",
    "                            dc_bboxes = total_dc_bboxes[i]\n",
    "                            det_bboxes = det_results[id]['bbox']\n",
    "                            if len(dc_bboxes) > 0:\n",
    "                                ious_dc_det = iou2d(torch.from_numpy(det_bboxes), torch.from_numpy(dc_bboxes), metric=1).numpy().T\n",
    "                                for j in range(len(dc_bboxes)):\n",
    "                                    for k in range(len(det_bboxes)):\n",
    "                                        if det_ignores[k] == 0 and scores[k] >= score_threshold and not assigned[k]:\n",
    "                                            if ious_dc_det[j, k] > CLS_MIN_IOU:\n",
    "                                                fp -= 1\n",
    "                                                assigned[k] = True\n",
    "                            \n",
    "                    tps.append(tp)\n",
    "                    fns.append(fn)\n",
    "                    fps.append(fp)\n",
    "                    if eval_type == 'bbox_2d':\n",
    "                        total_aos.append(aos)\n",
    "\n",
    "                tps, fns, fps = np.array(tps), np.array(fns), np.array(fps)\n",
    "\n",
    "                precisions = tps / (tps + fns) # actually this is recalls\n",
    "                # precisions = tps / (tps + fps)\n",
    "                for i in range(len(score_thresholds)):\n",
    "                    precisions[i] = np.max(precisions[i:])\n",
    "                \n",
    "                sums_AP = 0\n",
    "                for i in range(0, len(score_thresholds), 4):\n",
    "                    sums_AP += precisions[i]\n",
    "                mAP = sums_AP / 11 * 100\n",
    "                eval_ap_results[cls].append(mAP)\n",
    "\n",
    "                if eval_type == 'bbox_2d':\n",
    "                    total_aos = np.array(total_aos)\n",
    "                    similarity = total_aos / (tps + fps)\n",
    "                    for i in range(len(score_thresholds)):\n",
    "                        similarity[i] = np.max(similarity[i:])\n",
    "                    sums_similarity = 0\n",
    "                    for i in range(0, len(score_thresholds), 4):\n",
    "                        sums_similarity += similarity[i]\n",
    "                    mSimilarity = sums_similarity / 11 * 100\n",
    "                    eval_aos_results[cls].append(mSimilarity)\n",
    "\n",
    "        print(f'=========={eval_type.upper()}==========')\n",
    "        print(f'=========={eval_type.upper()}==========', file=f)\n",
    "        for k, v in eval_ap_results.items():\n",
    "            print(f'{k} AP@{MIN_IOUS[k][e_ind]}: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}')\n",
    "            print(f'{k} AP@{MIN_IOUS[k][e_ind]}: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}', file=f)\n",
    "        if eval_type == 'bbox_2d':\n",
    "            print(f'==========AOS==========')\n",
    "            print(f'==========AOS==========', file=f)\n",
    "            for k, v in eval_aos_results.items():\n",
    "                print(f'{k} AOS@{MIN_IOUS[k][e_ind]}: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}')\n",
    "                print(f'{k} AOS@{MIN_IOUS[k][e_ind]}: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}', file=f)\n",
    "        \n",
    "        overall_results[eval_type] = np.mean(list(eval_ap_results.values()), 0)\n",
    "        if eval_type == 'bbox_2d':\n",
    "            overall_results['AOS'] = np.mean(list(eval_aos_results.values()), 0)\n",
    "    \n",
    "    print(f'\\n==========Overall==========')\n",
    "    print(f'\\n==========Overall==========', file=f)\n",
    "    for k, v in overall_results.items():\n",
    "        print(f'{k} AP: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}')\n",
    "        print(f'{k} AP: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}', file=f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_losses(bbox_cls_pred0, bbox_pred0, bbox_dir_cls_pred0, anchor_target_dict):\n",
    "    \n",
    "    ################# Full features #################\n",
    "    bbox_cls_pred0 = bbox_cls_pred0.permute(0, 2, 3, 1).reshape(-1, args.nclasses)\n",
    "    bbox_pred0 = bbox_pred0.permute(0, 2, 3, 1).reshape(-1, 7)\n",
    "    bbox_dir_cls_pred0 = bbox_dir_cls_pred0.permute(0, 2, 3, 1).reshape(-1, 2)\n",
    "\n",
    "    batched_bbox_labels = anchor_target_dict['batched_labels'].reshape(-1)\n",
    "    batched_label_weights = anchor_target_dict['batched_label_weights'].reshape(-1)\n",
    "    batched_bbox_reg = anchor_target_dict['batched_bbox_reg'].reshape(-1, 7)\n",
    "    batched_dir_labels = anchor_target_dict['batched_dir_labels'].reshape(-1)\n",
    "\n",
    "    pos_idx = (batched_bbox_labels >= 0) & (batched_bbox_labels < args.nclasses)\n",
    "\n",
    "    bbox_pred0 = bbox_pred0[pos_idx]\n",
    "    batched_bbox_reg = batched_bbox_reg[pos_idx]\n",
    "    batched_bbox_reg0 = batched_bbox_reg.clone()\n",
    "\n",
    "    # sin(a - b) = sin(a)*cos(b) - cos(a)*sin(b)\n",
    "    bbox_pred0[:, -1] = torch.sin(bbox_pred0[:, -1].clone()) * torch.cos(batched_bbox_reg[:, -1].clone())\n",
    "    batched_bbox_reg0[:, -1] = torch.cos(bbox_pred0[:, -1].clone()) * torch.sin(batched_bbox_reg[:, -1].clone())\n",
    "    bbox_dir_cls_pred0 = bbox_dir_cls_pred0[pos_idx]\n",
    "    batched_dir_labels = batched_dir_labels[pos_idx]\n",
    "    num_cls_pos = (batched_bbox_labels < args.nclasses).sum()\n",
    "    bbox_cls_pred0 = bbox_cls_pred0[batched_label_weights > 0]\n",
    "\n",
    "\n",
    "    batched_bbox_labels[batched_bbox_labels < 0] = args.nclasses\n",
    "    batched_bbox_labels = batched_bbox_labels[batched_label_weights > 0]\n",
    "\n",
    "    loss_dict0 = loss_func(bbox_cls_pred=bbox_cls_pred0,\n",
    "                            bbox_pred=bbox_pred0,\n",
    "                            bbox_dir_cls_pred=bbox_dir_cls_pred0,\n",
    "                            batched_labels=batched_bbox_labels, \n",
    "                            num_cls_pos=num_cls_pos, \n",
    "                            batched_bbox_reg=batched_bbox_reg0, \n",
    "                            batched_dir_labels=batched_dir_labels)\n",
    "\n",
    "    return loss_dict0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize(model, lambd = 1.1):\n",
    "\n",
    "    A = model.pillar_encoder.global_masks[0]\n",
    "    # B = torch.tensor([lambd ** i for i in range(len(A))], dtype=torch.float32).unsqueeze(0).to(A.device)\n",
    "    _, indices = torch.sort(A, dim=1, descending=True)\n",
    "    B = torch.pow(lambd, indices)\n",
    "    regularized_loss = torch.sum(A * B)\n",
    "\n",
    "\n",
    "    A = model.neck.global_masks[0]\n",
    "    _, indices = torch.sort(A, dim=1, descending=True)\n",
    "    B = torch.pow(lambd, indices)\n",
    "    regularized_loss += torch.sum(A * B)\n",
    "\n",
    "\n",
    "    for A in model.backbone.global_masks:\n",
    "        _, indices = torch.sort(A, dim=1, descending=True)\n",
    "        B = torch.pow(lambd, indices)\n",
    "        regularized_loss += torch.sum(A * B)\n",
    "\n",
    "\n",
    "    return regularized_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bugicugi(bbox_cls_pred0, bbox_pred0, bbox_dir_cls_pred0, anchor_target_dict):\n",
    "    bbox_cls_pred0 = bbox_cls_pred0.permute(0, 2, 3, 1).reshape(-1, args.nclasses)\n",
    "    bbox_pred0 = bbox_pred0.permute(0, 2, 3, 1).reshape(-1, 7)\n",
    "    bbox_dir_cls_pred0 = bbox_dir_cls_pred0.permute(0, 2, 3, 1).reshape(-1, 2)\n",
    "\n",
    "    batched_bbox_labels = anchor_target_dict['batched_labels'].reshape(-1)\n",
    "    batched_label_weights = anchor_target_dict['batched_label_weights'].reshape(-1)\n",
    "    batched_bbox_reg = anchor_target_dict['batched_bbox_reg'].reshape(-1, 7)\n",
    "    batched_dir_labels = anchor_target_dict['batched_dir_labels'].reshape(-1)\n",
    "\n",
    "    pos_idx = (batched_bbox_labels >= 0) & (batched_bbox_labels < args.nclasses)\n",
    "\n",
    "    bbox_pred0 = bbox_pred0[pos_idx]\n",
    "\n",
    "    batched_bbox_reg = batched_bbox_reg[pos_idx]\n",
    "    batched_bbox_reg0 = batched_bbox_reg.clone()\n",
    "\n",
    "    # sin(a - b) = sin(a)*cos(b) - cos(a)*sin(b)\n",
    "    bbox_pred0[:, -1] = torch.sin(bbox_pred0[:, -1].clone()) * torch.cos(batched_bbox_reg[:, -1].clone())\n",
    "    batched_bbox_reg0[:, -1] = torch.cos(bbox_pred0[:, -1].clone()) * torch.sin(batched_bbox_reg[:, -1].clone())\n",
    "    bbox_dir_cls_pred0 = bbox_dir_cls_pred0[pos_idx]\n",
    "\n",
    "\n",
    "    batched_dir_labels = batched_dir_labels[pos_idx]\n",
    "\n",
    "    num_cls_pos = (batched_bbox_labels < args.nclasses).sum()\n",
    "\n",
    "    bbox_cls_pred0 = bbox_cls_pred0[batched_label_weights > 0]\n",
    "\n",
    "\n",
    "    batched_bbox_labels[batched_bbox_labels < 0] = args.nclasses\n",
    "    batched_bbox_labels = batched_bbox_labels[batched_label_weights > 0]\n",
    "\n",
    "    loss_dict0 = loss_func(bbox_cls_pred=bbox_cls_pred0,\n",
    "                            bbox_pred=bbox_pred0,\n",
    "                            bbox_dir_cls_pred=bbox_dir_cls_pred0,\n",
    "                            batched_labels=batched_bbox_labels, \n",
    "                            num_cls_pos=num_cls_pos, \n",
    "                            batched_bbox_reg=batched_bbox_reg0, \n",
    "                            batched_dir_labels=batched_dir_labels)\n",
    "    return loss_dict0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pointpillars.load_state_dict(torch.load(\"logs/pillar_sequence_memory_gating_binary/checkpoints/epoch_60.pth\"))\n",
    "# checkpoint = torch.load(\"logs/pillar_sequence_mem_lin_gat_9_param_share_test/checkpoints/epoch_3.pth.tar\")\n",
    "# pointpillars.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch0 = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1317 [00:00<?, ?it/s]/home/sayeed/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541702/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  0%|          | 1/1317 [00:11<4:21:20, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2518012523651123\n",
      "818667800000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1317 [00:12<1:53:26,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2617011070251465\n",
      "817247700000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1317 [00:12<1:05:40,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0039005279541016\n",
      "813866100000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1317 [00:13<43:23,  1.98s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0528345108032227\n",
      "812333540000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1317 [00:13<30:59,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.114917516708374\n",
      "813421000000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/1317 [00:14<23:26,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.860959768295288\n",
      "820136700000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1317 [00:14<18:48,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9049129486083984\n",
      "816224000000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1317 [00:14<15:34,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.037095546722412\n",
      "819832750000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1317 [00:15<13:34,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9598960876464844\n",
      "821068100000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1317 [00:15<12:10,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.091407537460327\n",
      "814060500000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1317 [00:16<11:11,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0662903785705566\n",
      "816598000000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1317 [00:16<10:40,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9626924991607666\n",
      "814635400000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/1317 [00:16<10:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3160245418548584\n",
      "820801300000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1317 [00:17<09:54,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1426830291748047\n",
      "816065260000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/1317 [00:17<09:37,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2557451725006104\n",
      "816168000000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/1317 [00:18<09:20,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0283327102661133\n",
      "816494200000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 17/1317 [00:18<09:46,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.923130989074707\n",
      "816321500000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 18/1317 [00:19<09:33,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.087209463119507\n",
      "817577100000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 19/1317 [00:19<09:33,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1256508827209473\n",
      "816671660000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1317 [00:19<09:26,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9273476600646973\n",
      "808109400000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1317 [00:20<09:27,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0781311988830566\n",
      "814177200000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1317 [00:20<09:17,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1037909984588623\n",
      "814656600000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 23/1317 [00:21<09:09,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.992594003677368\n",
      "819595100000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 24/1317 [00:21<09:09,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2503206729888916\n",
      "815624800000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 25/1317 [00:22<08:59,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.066269874572754\n",
      "817002000000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 26/1317 [00:22<09:06,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8319811820983887\n",
      "815481350000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 27/1317 [00:22<09:02,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.109323501586914\n",
      "820827000000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 28/1317 [00:23<09:06,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0663890838623047\n",
      "815942600000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 29/1317 [00:23<09:02,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.073502779006958\n",
      "820281850000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 30/1317 [00:24<08:58,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9670779705047607\n",
      "820709260000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 31/1317 [00:24<09:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.968139886856079\n",
      "817328700000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 32/1317 [00:25<09:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1072347164154053\n",
      "819646460000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1317 [00:25<09:04,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0144104957580566\n",
      "819279800000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 34/1317 [00:25<08:57,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8792693614959717\n",
      "817258200000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 35/1317 [00:26<08:54,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.328474760055542\n",
      "820042500000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 36/1317 [00:26<09:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.192401885986328\n",
      "818369440000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 37/1317 [00:27<08:59,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9484236240386963\n",
      "818728140000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 38/1317 [00:27<09:04,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0618460178375244\n",
      "817769360000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 39/1317 [00:27<08:58,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9739420413970947\n",
      "818734800000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 40/1317 [00:28<08:59,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1131739616394043\n",
      "811495700000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 41/1317 [00:28<09:06,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.768773078918457\n",
      "820185140000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 42/1317 [00:29<09:48,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9284136295318604\n",
      "820117560000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 43/1317 [00:29<09:38,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8334028720855713\n",
      "815546440000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 44/1317 [00:30<09:20,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7546775341033936\n",
      "811865100000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 45/1317 [00:30<09:11,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1833605766296387\n",
      "811553500000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 46/1317 [00:31<09:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2850351333618164\n",
      "816725400000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 47/1317 [00:31<08:58,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.804124116897583\n",
      "820206100000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 48/1317 [00:31<09:04,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.03832745552063\n",
      "817091800000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 49/1317 [00:32<08:58,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0606930255889893\n",
      "815665560000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 50/1317 [00:32<09:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.884445905685425\n",
      "822126200000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 51/1317 [00:33<08:56,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.306450128555298\n",
      "821824600000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 52/1317 [00:33<09:05,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8744587898254395\n",
      "817787800000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 53/1317 [00:34<09:01,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9892704486846924\n",
      "818387900000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 54/1317 [00:34<09:11,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9921603202819824\n",
      "815106000000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 55/1317 [00:34<09:07,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6194283962249756\n",
      "816161600000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 56/1317 [00:35<08:59,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.977078676223755\n",
      "817944500000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 57/1317 [00:35<08:57,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9652838706970215\n",
      "820256950000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 58/1317 [00:36<08:53,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.868042469024658\n",
      "819380640000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 59/1317 [00:36<08:47,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.977863311767578\n",
      "814450000000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 60/1317 [00:37<08:56,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.891096353530884\n",
      "820120650000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 61/1317 [00:37<08:51,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.145322322845459\n",
      "816799800000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 62/1317 [00:37<08:47,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.902412176132202\n",
      "821171000000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 63/1317 [00:38<08:43,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.150188446044922\n",
      "823897500000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 64/1317 [00:38<08:39,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7927167415618896\n",
      "822831600000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 65/1317 [00:39<08:48,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.858840227127075\n",
      "817072700000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 66/1317 [00:39<08:48,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0046043395996094\n",
      "821429740000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 67/1317 [00:39<08:43,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1365883350372314\n",
      "819951700000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 68/1317 [00:40<08:39,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.791889190673828\n",
      "826005000000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 69/1317 [00:40<08:33,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.950295925140381\n",
      "823712850000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 70/1317 [00:41<08:44,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.983304738998413\n",
      "817773050000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 71/1317 [00:41<08:39,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.882347345352173\n",
      "824676200000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 72/1317 [00:42<08:48,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8705649375915527\n",
      "820508300000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 73/1317 [00:42<08:44,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9950575828552246\n",
      "815262400000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 74/1317 [00:42<08:46,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.096813678741455\n",
      "820913740000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 75/1317 [00:43<08:37,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8376870155334473\n",
      "817877500000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 76/1317 [00:43<08:35,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.008801221847534\n",
      "819943400000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 77/1317 [00:44<08:41,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0917837619781494\n",
      "821008160000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 78/1317 [00:44<08:35,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7645859718322754\n",
      "815107750000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 79/1317 [00:44<08:44,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8438944816589355\n",
      "819049660000000.0\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "training_loss0 = []\n",
    "training_gloss0 = []\n",
    "\n",
    "epoch0 = 0\n",
    "global_step=0\n",
    "\n",
    "for epoch in range(epoch0, args.max_epoch):\n",
    "# for epoch in range(1):\n",
    "    epoch_loss0 = 0\n",
    "    epoch_gLoss0 = 0\n",
    "\n",
    "    train_indices = np.random.randint(train_dataset_length, size=train_dataset_batch_count)\n",
    "\n",
    "    print('=' * 20, epoch, '=' * 20)\n",
    "\n",
    "    train_step, val_step = 0, 0\n",
    "\n",
    "    pointpillars.train()\n",
    "\n",
    "    for i, data_dict in enumerate(tqdm(train_dataloader)):\n",
    "        if i > 500:\n",
    "            break\n",
    "        if not args.no_cuda:\n",
    "            # move the tensors to the cuda\n",
    "            for key in data_dict:\n",
    "                for j, item in enumerate(data_dict[key]):\n",
    "                    if torch.is_tensor(item):\n",
    "                        data_dict[key][j] = data_dict[key][j].cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batched_pts = data_dict['batched_pts']\n",
    "        batched_gt_bboxes = data_dict['batched_gt_bboxes']\n",
    "        batched_labels = data_dict['batched_labels']\n",
    "        batched_difficulty = data_dict['batched_difficulty']\n",
    "\n",
    "        ################# Full features #################\n",
    "\n",
    "        # bbox_cls_pred0, bbox_pred0, bbox_dir_cls_pred0, anchor_target_dict0 = pointpillars(batched_pts=batched_pts, \n",
    "        #                             mode='train',\n",
    "        #                             batched_gt_bboxes=batched_gt_bboxes, \n",
    "        #                             batched_gt_labels=batched_labels)\n",
    "\n",
    "        # loss_dict0 = bugicugi(bbox_cls_pred0, bbox_pred0, bbox_dir_cls_pred0, anchor_target_dict0)\n",
    "\n",
    "\n",
    "        # loss = loss_dict0['total_loss']  \n",
    "        # loss.backward()\n",
    "\n",
    "        # bbox_cls_pred0, bbox_pred0, bbox_dir_cls_pred0, anchor_target_dict0, \\\n",
    "        #         bbox_cls_pred1, bbox_pred1, bbox_dir_cls_pred1, anchor_target_dict1, \\\n",
    "        #             bbox_cls_pred2, bbox_pred2, bbox_dir_cls_pred2, anchor_target_dict2 = pointpillars(batched_pts=batched_pts, \n",
    "        #                             mode='train',\n",
    "        #                             batched_gt_bboxes=batched_gt_bboxes, \n",
    "        #                             batched_gt_labels=batched_labels)\n",
    "\n",
    "        bbox_cls_pred0, bbox_pred0, bbox_dir_cls_pred0, anchor_target_dict0 = pointpillars(batched_pts=batched_pts, \n",
    "                                    mode='train',\n",
    "                                    batched_gt_bboxes=batched_gt_bboxes, \n",
    "                                    batched_gt_labels=batched_labels, level = 0)\n",
    "        \n",
    "        loss_dict0 = bugicugi(bbox_cls_pred0, bbox_pred0, bbox_dir_cls_pred0, anchor_target_dict0)\n",
    "        # loss_dict1 = bugicugi(bbox_cls_pred1, bbox_pred1, bbox_dir_cls_pred1, anchor_target_dict1)\n",
    "        # loss_dict2 = bugicugi(bbox_cls_pred2, bbox_pred2, bbox_dir_cls_pred2, anchor_target_dict2)\n",
    "\n",
    "        detection_loss = loss_dict0['total_loss']\n",
    "        regularizer_loss = regularize(pointpillars)\n",
    "        # loss = loss_dict0['total_loss'] +  loss_dict1['total_loss'] +  loss_dict2['total_loss']  \n",
    "\n",
    "        gamma = 1e-14\n",
    "        loss = detection_loss + regularizer_loss*gamma\n",
    "\n",
    "        loss.backward()\n",
    "        # loss_dict1['total_loss'].backward()\n",
    "        # loss_dict2['total_loss'].backward()\n",
    "        # loss.backward()\n",
    "        d_loss = detection_loss.item()\n",
    "        r_loss = regularizer_loss.detach().cpu().numpy()\n",
    "        epoch_loss0 += d_loss\n",
    "        epoch_gLoss0 += r_loss\n",
    "\n",
    "        # print(d_loss)\n",
    "        # print(r_loss)\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(pointpillars.parameters(), max_norm=35)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    \n",
    "        train_step += 1\n",
    "\n",
    "        global_step = 2*train_dataset_batch_count*epoch + train_step\n",
    "\n",
    "        # if global_step % args.log_freq == 0:\n",
    "        #     save_summary(writer, loss_dict, global_step, 'train', p,\n",
    "        #                     lr=optimizer.param_groups[0]['lr'], \n",
    "        #                     momentum=optimizer.param_groups[0]['betas'][0],\n",
    "        #                     model=pointpillars, data=data_cuda, flag=model_flag)\n",
    "\n",
    "    training_loss0.append(epoch_loss0)\n",
    "    training_gloss0.append(epoch_gLoss0)\n",
    "    print(training_loss0)\n",
    "\n",
    "    if epoch % args.ckpt_freq_epoch == 0:\n",
    "\n",
    "        checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': pointpillars.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }   \n",
    "        torch.save(checkpoint, os.path.join(saved_ckpt_path, f'epoch_{epoch+1}.pth.tar'))\n",
    "    ###################################### Validation ######################################\n",
    "\n",
    "    if (epoch % args.val_freq_epoch) == 0:\n",
    "    # if (epoch % args.val_freq_epoch) == 0:\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(np.array(training_loss0))\n",
    "        plt.plot(np.array(training_gloss0))\n",
    "        plt.title(\"Training Loss\")\n",
    "        plt.legend([\"loss\", \"g_loss\"])\n",
    "        plt.show()\n",
    "\n",
    "        ################################### Validation ###################################\n",
    "\n",
    "        pointpillars.eval()\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                format_results = {}\n",
    "                print('Predicting and Formatting the results.')\n",
    "                for i, data_dict in enumerate(tqdm(val_dataloader)):\n",
    "                    if not args.no_cuda:\n",
    "                        # move the tensors to the cuda\n",
    "                        for key in data_dict:\n",
    "                            for j, item in enumerate(data_dict[key]):\n",
    "                                if torch.is_tensor(item):\n",
    "                                    data_dict[key][j] = data_dict[key][j].cuda()\n",
    "                    \n",
    "                    batched_pts = data_dict['batched_pts']\n",
    "                    batched_gt_bboxes = data_dict['batched_gt_bboxes']\n",
    "                    batched_labels = data_dict['batched_labels']\n",
    "                    batched_difficulty = data_dict['batched_difficulty']\n",
    "                    batch_results0  = pointpillars(batched_pts=batched_pts,\n",
    "                                            mode='val0',\n",
    "                                            batched_gt_bboxes=batched_gt_bboxes, \n",
    "                                            batched_gt_labels=batched_labels)\n",
    "\n",
    "                    for j, result in enumerate(batch_results0):\n",
    "                        format_result = {\n",
    "                            'name': [],\n",
    "                            'truncated': [],\n",
    "                            'occluded': [],\n",
    "                            'alpha': [],\n",
    "                            'bbox': [],\n",
    "                            'dimensions': [],\n",
    "                            'location': [],\n",
    "                            'rotation_y': [],\n",
    "                            'score': []\n",
    "                        }\n",
    "                        \n",
    "                        calib_info = data_dict['batched_calib_info'][j]\n",
    "                        tr_velo_to_cam = calib_info['Tr_velo_to_cam'].astype(np.float32)\n",
    "                        r0_rect = calib_info['R0_rect'].astype(np.float32)\n",
    "                        P2 = calib_info['P2'].astype(np.float32)\n",
    "                        image_shape = data_dict['batched_img_info'][j]['image_shape']\n",
    "                        idx = data_dict['batched_img_info'][j]['image_idx']\n",
    "                        result_filter = keep_bbox_from_image_range(result, tr_velo_to_cam, r0_rect, P2, image_shape)\n",
    "                        result_filter = keep_bbox_from_lidar_range(result_filter, pcd_limit_range)\n",
    "\n",
    "                        lidar_bboxes = result_filter['lidar_bboxes']\n",
    "                        labels, scores = result_filter['labels'], result_filter['scores']\n",
    "                        bboxes2d, camera_bboxes = result_filter['bboxes2d'], result_filter['camera_bboxes']\n",
    "                        \n",
    "                        for lidar_bbox, label, score, bbox2d, camera_bbox in \\\n",
    "                            zip(lidar_bboxes, labels, scores, bboxes2d, camera_bboxes):\n",
    "                            format_result['name'].append(LABEL2CLASSES[label])\n",
    "                            format_result['truncated'].append(0.0)\n",
    "                            format_result['occluded'].append(0)\n",
    "                            alpha = camera_bbox[6] - np.arctan2(camera_bbox[0], camera_bbox[2])\n",
    "                            format_result['alpha'].append(alpha)\n",
    "                            format_result['bbox'].append(bbox2d)\n",
    "                            format_result['dimensions'].append(camera_bbox[3:6])\n",
    "                            format_result['location'].append(camera_bbox[:3])\n",
    "                            format_result['rotation_y'].append(camera_bbox[6])\n",
    "                            format_result['score'].append(score)\n",
    "                        \n",
    "                        write_label(format_result, os.path.join(args.saved_path_exact, f'{idx:06d}.txt'))\n",
    "\n",
    "                        format_results[idx] = {k:np.array(v) for k, v in format_result.items()}\n",
    "                \n",
    "                write_pickle(format_results, os.path.join(args.saved_path, 'results.pkl'))\n",
    "\n",
    "            print('Evaluating.. Please wait several seconds.')\n",
    "            do_eval(format_results, val_dataset.data_infos, CLASSES, args.saved_path)\n",
    "        except:\n",
    "            None\n",
    "        # do_eval(format_results, dict(islice(val_dataset.data_infos.items(), i)), CLASSES, args.saved_path)\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loss0[0] < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting and Formatting the results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/433 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/433 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m image_shape \u001b[38;5;241m=\u001b[39m data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatched_img_info\u001b[39m\u001b[38;5;124m'\u001b[39m][j][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_shape\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     41\u001b[0m idx \u001b[38;5;241m=\u001b[39m data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatched_img_info\u001b[39m\u001b[38;5;124m'\u001b[39m][j][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 42\u001b[0m result_filter \u001b[38;5;241m=\u001b[39m \u001b[43mkeep_bbox_from_image_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_velo_to_cam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr0_rect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m result_filter \u001b[38;5;241m=\u001b[39m keep_bbox_from_lidar_range(result_filter, pcd_limit_range)\n\u001b[1;32m     45\u001b[0m lidar_bboxes \u001b[38;5;241m=\u001b[39m result_filter[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlidar_bboxes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/uncertainty_estimation/point_cloud/PointPillars/utils/process.py:564\u001b[0m, in \u001b[0;36mkeep_bbox_from_image_range\u001b[0;34m(result, tr_velo_to_cam, r0_rect, P2, image_shape)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03mresult: dict(lidar_bboxes, labels, scores)\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03mtr_velo_to_cam: shape=(4, 4)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;124;03mreturn: dict(lidar_bboxes, labels, scores, bboxes2d, camera_bboxes)\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    562\u001b[0m h, w \u001b[38;5;241m=\u001b[39m image_shape\n\u001b[0;32m--> 564\u001b[0m lidar_bboxes \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlidar_bboxes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    565\u001b[0m labels \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    566\u001b[0m scores \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "pointpillars.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    format_results = {}\n",
    "    print('Predicting and Formatting the results.')\n",
    "    for i, data_dict in enumerate(tqdm(val_dataloader)):\n",
    "        if not args.no_cuda:\n",
    "            # move the tensors to the cuda\n",
    "            for key in data_dict:\n",
    "                for j, item in enumerate(data_dict[key]):\n",
    "                    if torch.is_tensor(item):\n",
    "                        data_dict[key][j] = data_dict[key][j].cuda()\n",
    "        \n",
    "        batched_pts = data_dict['batched_pts']\n",
    "        batched_gt_bboxes = data_dict['batched_gt_bboxes']\n",
    "        batched_labels = data_dict['batched_labels']\n",
    "        batched_difficulty = data_dict['batched_difficulty']\n",
    "        batch_results0  = pointpillars(batched_pts=batched_pts,\n",
    "                                mode='val0',\n",
    "                                batched_gt_bboxes=batched_gt_bboxes, \n",
    "                                batched_gt_labels=batched_labels)\n",
    "\n",
    "        for j, result in enumerate(batch_results0):\n",
    "            format_result = {\n",
    "                'name': [],\n",
    "                'truncated': [],\n",
    "                'occluded': [],\n",
    "                'alpha': [],\n",
    "                'bbox': [],\n",
    "                'dimensions': [],\n",
    "                'location': [],\n",
    "                'rotation_y': [],\n",
    "                'score': []\n",
    "            }\n",
    "            \n",
    "            calib_info = data_dict['batched_calib_info'][j]\n",
    "            tr_velo_to_cam = calib_info['Tr_velo_to_cam'].astype(np.float32)\n",
    "            r0_rect = calib_info['R0_rect'].astype(np.float32)\n",
    "            P2 = calib_info['P2'].astype(np.float32)\n",
    "            image_shape = data_dict['batched_img_info'][j]['image_shape']\n",
    "            idx = data_dict['batched_img_info'][j]['image_idx']\n",
    "            result_filter = keep_bbox_from_image_range(result, tr_velo_to_cam, r0_rect, P2, image_shape)\n",
    "            result_filter = keep_bbox_from_lidar_range(result_filter, pcd_limit_range)\n",
    "\n",
    "            lidar_bboxes = result_filter['lidar_bboxes']\n",
    "            labels, scores = result_filter['labels'], result_filter['scores']\n",
    "            bboxes2d, camera_bboxes = result_filter['bboxes2d'], result_filter['camera_bboxes']\n",
    "            \n",
    "            for lidar_bbox, label, score, bbox2d, camera_bbox in \\\n",
    "                zip(lidar_bboxes, labels, scores, bboxes2d, camera_bboxes):\n",
    "                format_result['name'].append(LABEL2CLASSES[label])\n",
    "                format_result['truncated'].append(0.0)\n",
    "                format_result['occluded'].append(0)\n",
    "                alpha = camera_bbox[6] - np.arctan2(camera_bbox[0], camera_bbox[2])\n",
    "                format_result['alpha'].append(alpha)\n",
    "                format_result['bbox'].append(bbox2d)\n",
    "                format_result['dimensions'].append(camera_bbox[3:6])\n",
    "                format_result['location'].append(camera_bbox[:3])\n",
    "                format_result['rotation_y'].append(camera_bbox[6])\n",
    "                format_result['score'].append(score)\n",
    "            \n",
    "            write_label(format_result, os.path.join(args.saved_path_exact, f'{idx:06d}.txt'))\n",
    "\n",
    "            format_results[idx] = {k:np.array(v) for k, v in format_result.items()}\n",
    "    \n",
    "    write_pickle(format_results, os.path.join(args.saved_path, 'results.pkl'))\n",
    "\n",
    "print('Evaluating.. Please wait several seconds.')\n",
    "do_eval(format_results, val_dataset.data_infos, CLASSES, args.saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([], [], []), ([], [], [])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(batch_results0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointpillars.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    format_results = {}\n",
    "    print('Predicting and Formatting the results.')\n",
    "    for i, data_dict in enumerate(tqdm(val_dataloader)):\n",
    "        if not args.no_cuda:\n",
    "            # move the tensors to the cuda\n",
    "            for key in data_dict:\n",
    "                for j, item in enumerate(data_dict[key]):\n",
    "                    if torch.is_tensor(item):\n",
    "                        data_dict[key][j] = data_dict[key][j].cuda()\n",
    "        \n",
    "        batched_pts = data_dict['batched_pts']\n",
    "        batched_gt_bboxes = data_dict['batched_gt_bboxes']\n",
    "        batched_labels = data_dict['batched_labels']\n",
    "        batched_difficulty = data_dict['batched_difficulty']\n",
    "        batch_results0  = pointpillars(batched_pts=batched_pts,\n",
    "                                mode='val2',\n",
    "                                batched_gt_bboxes=batched_gt_bboxes, \n",
    "                                batched_gt_labels=batched_labels)\n",
    "\n",
    "        for j, result in enumerate(batch_results0):\n",
    "            format_result = {\n",
    "                'name': [],\n",
    "                'truncated': [],\n",
    "                'occluded': [],\n",
    "                'alpha': [],\n",
    "                'bbox': [],\n",
    "                'dimensions': [],\n",
    "                'location': [],\n",
    "                'rotation_y': [],\n",
    "                'score': []\n",
    "            }\n",
    "            \n",
    "            calib_info = data_dict['batched_calib_info'][j]\n",
    "            tr_velo_to_cam = calib_info['Tr_velo_to_cam'].astype(np.float32)\n",
    "            r0_rect = calib_info['R0_rect'].astype(np.float32)\n",
    "            P2 = calib_info['P2'].astype(np.float32)\n",
    "            image_shape = data_dict['batched_img_info'][j]['image_shape']\n",
    "            idx = data_dict['batched_img_info'][j]['image_idx']\n",
    "            result_filter = keep_bbox_from_image_range(result, tr_velo_to_cam, r0_rect, P2, image_shape)\n",
    "            result_filter = keep_bbox_from_lidar_range(result_filter, pcd_limit_range)\n",
    "\n",
    "            lidar_bboxes = result_filter['lidar_bboxes']\n",
    "            labels, scores = result_filter['labels'], result_filter['scores']\n",
    "            bboxes2d, camera_bboxes = result_filter['bboxes2d'], result_filter['camera_bboxes']\n",
    "            \n",
    "            for lidar_bbox, label, score, bbox2d, camera_bbox in \\\n",
    "                zip(lidar_bboxes, labels, scores, bboxes2d, camera_bboxes):\n",
    "                format_result['name'].append(LABEL2CLASSES[label])\n",
    "                format_result['truncated'].append(0.0)\n",
    "                format_result['occluded'].append(0)\n",
    "                alpha = camera_bbox[6] - np.arctan2(camera_bbox[0], camera_bbox[2])\n",
    "                format_result['alpha'].append(alpha)\n",
    "                format_result['bbox'].append(bbox2d)\n",
    "                format_result['dimensions'].append(camera_bbox[3:6])\n",
    "                format_result['location'].append(camera_bbox[:3])\n",
    "                format_result['rotation_y'].append(camera_bbox[6])\n",
    "                format_result['score'].append(score)\n",
    "            \n",
    "            write_label(format_result, os.path.join(args.saved_path_exact, f'{idx:06d}.txt'))\n",
    "\n",
    "            format_results[idx] = {k:np.array(v) for k, v in format_result.items()}\n",
    "    \n",
    "    write_pickle(format_results, os.path.join(args.saved_path, 'results.pkl'))\n",
    "\n",
    "print('Evaluating.. Please wait several seconds.')\n",
    "do_eval(format_results, val_dataset.data_infos, CLASSES, args.saved_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
