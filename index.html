<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Latent Pruning for Compute Optimization in 3D Object Detection Frameworks</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Latent Pruning for Compute Optimization in 3D Object Detection Frameworks</h1>


          
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Mir Sayeed Mohammad</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Mizanur Rahaman Nayan</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Sujoy Mondal</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Uday Kamal</a>
                  </span>
                  </div>  
     
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Georgia Institute of Technology<br>CS 7641</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Problem Definition</h2>
        <div class="content has-text-justified">
          <p>
           	LIDAR scanners are crucial components in autonomous systems, providing point cloud data that is integral for perceiving surroundings. However, processing this unstructured data in object detection frameworks involves significant computational overhead. Current methods, like the PointPillars architecture, convert point clouds into a structured format resembling voxels, leading to computational redundancy due to sparse data representation.
Efficient processing of LIDAR data is essential for real-time applications like autonomous driving. The majority of computation in object detection frameworks occurs during the conversion of voxelized data in the feature extraction stage. This bottleneck necessitates optimization to enhance computational efficiency without compromising detection accuracy. Current approaches, such as Matryoshka Representation Learning, offer promising avenues by selectively pruning feature channels, thereby reducing computational load while maintaining acceptable detection performance levels.
This project aims to explore and optimize the integration of network pruning techniques within the PointPillars framework. By leveraging adaptive latent regularization, we seek to significantly reduce computation and memory requirements while evaluating its impact on detection accuracy across different scenes and object classes. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Literature Review -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Literature Review</h2>
        <div class="content has-text-justified">
          <p>
            Structured pruning methods, such as CoFi, combine coarse and fine-grained units with layer-wise distillation to enhance model compression and inference speed without significant accuracy loss (Yu et al.; Wang et al.). Layer and head pruning in Transformer models also effectively reduce model size while maintaining performance (Yu et al.). Regularization-based pruning methods like L1 regularization and growing regularization gradually drive unimportant weights to zero before pruning, balancing parameter reduction and accuracy (Yeh et al.; Wang et al., "Neural Pruning via Growing Regularization"). Importance-based pruning uses criteria like neuron importance score propagation (NISP) and Taylor expansion-based methods to iteratively prune less important neurons, retaining essential features and performance (Yu et al.; Molchanov et al.; Sunil and Salem; Liu et al.). These techniques collectively improve the efficiency and performance of neural networks by systematically reducing their complexity.
          </p>
          <h2>References</h2>
          <ol>
            <li>
              Yu, Chenglin, et al. "Structured Pruning Learns Compact and Accurate Models." <em>arXiv</em>, 2022.
          </li>
          <li>
              Wang, Jiaxiang, et al. "Structured Pruning for Deep Convolutional Neural Networks: A Survey." <em>arXiv</em>, 2023.
          </li>
          <li>
              Yeh, Chih-Kuan, et al. "Deep Trim: Revisiting L1 Regularization for Connection Pruning of Deep Networks." <em>Papers with Code</em>, 2019.
          </li>
          <li>
              Wang, Jiaxiang, et al. "Neural Pruning via Growing Regularization." <em>arXiv</em>, 2020.
          </li>
          <li>
              Yu, Ritchie, et al. "NISP: Pruning Networks Using Neuron Importance Score Propagation." <em>arXiv</em>, 2017.
          </li>
          <li>
              Molchanov, Pavlo, et al. "Importance Estimation for Neural Network Pruning." <em>arXiv</em>, 2019.
          </li>
          <li>
              Sunil, Vadera, and Salem Ameen. "Methods for Pruning Deep Neural Networks." <em>arXiv</em>, 2020.
          </li>
          <li>
              Liu, Zhuang, et al. "Rethinking the Value of Network Pruning." <em>arXiv</em>, 2019.
          </li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->








  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            </a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
