<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Latent Pruning for Compute Optimization in 3D Object Detection Frameworks</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Latent Pruning for Compute Optimization in 3D Object Detection Frameworks</h1>


          
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Mir Sayeed Mohammad</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Mizanur Rahaman Nayan</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Sujoy Mondal</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Uday Kamal</a>
                  </span>
                  </div>  
     
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Georgia Institute of Technology<br>CS 7641</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Our work aims to reduce the computation in a deep neural network model deployed in 3D object detection task by removing channels in different model layers and optimizing inference. Structured pruning methods, such as CoFi, combine coarse and fine-grained units with layer-wise distillation to enhance model compression and inference speed without significant accuracy loss (Yu et al.; Wang et al.). Layer and head pruning in Transformer models also effectively reduce model size while maintaining performance (Yu et al.). Regularization-based pruning methods like L1 regularization and growing regularization gradually drive unimportant weights to zero before pruning, balancing parameter reduction and accuracy (Yeh et al.; Wang et al., "Neural Pruning via Growing Regularization"). Importance-based pruning uses criteria like neuron importance score propagation (NISP) and Taylor expansion-based methods to iteratively prune less important neurons, retaining essential features and performance (Yu et al.; Molchanov et al.; Sunil and Salem; Liu et al.). These techniques collectively improve the efficiency and performance of neural networks by systematically reducing their complexity.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Problem Definition</h2>
        <div class="content has-text-justified">
          <p>
           	LIDAR scanners are crucial components in autonomous systems, providing point cloud data that is integral for perceiving surroundings. However, processing this unstructured data in object detection frameworks involves significant computational overhead. Current methods, like the PointPillars (Lang, Alex H., et al.) architecture, convert point clouds into a structured format resembling voxels, leading to computational redundancy due to sparse data representation.
Efficient processing of LIDAR data is essential for real-time applications like autonomous driving. The majority of computation in object detection frameworks occurs during the conversion of voxelized data in the feature extraction stage. This bottleneck necessitates optimization to enhance computational efficiency without compromising detection accuracy. Current approaches, such as Matryoshka Representation Learning, offer promising avenues by selectively pruning feature channels, thereby reducing computational load while maintaining acceptable detection performance levels.
This project aims to explore and optimize the integration of network pruning techniques within the PointPillars framework. By leveraging adaptive latent regularization, we seek to significantly reduce computation and memory requirements while evaluating its impact on detection accuracy across different scenes and object classes. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methods</h2>
        <div class="content has-text-justified">
          <p>
            Pointcloud data is a framewise stream of points that reflect LASER in the Cartesian coordinate system. For object detection in pointcloud, the space is first converted to a grid structure called voxels. In the PointPillars architecture, the points are first filtered within a field of view and range from the source. Then the points are grouped into pillars in the x-y plane. Points in each pillar are augmented with additional points, ensuring each pillar contains the same number of points. Then the pillars individually pass through an invariant dense layer creating a fixed number of features. All the features from the x-y plane create 2D pseudo images. During the preprocessing and pillar encoding, noise is added to the data as well to compensate for sensor uncertainty. Rotation, flipping etc are also other augmentation methods. 
          </p> <p>
            Some of the widely used algorithms in object detection frameworks are anchor generation, bounding box encoding and non-max suppression of candidate boundingboxes. Models like PointNet, PointNet++, PV-RCNN, VoxelNet, F-ConvNet etc are used for 3D object detection. In the most common object detection pipeline, there are a few modules called the encoder, backbone and the model head. The dense backbone is responsible for feature processing and contains most of the computation of the model. Our aim is to make our learning approach model agnostic such that the pruning method should be extendable to all convolution/dense layer based neural network architectures. 
            <img src="figs/pointpillars.png" alt="PointPillars architecture">
          </p><p>
            Our work primarily works with the optimization of model architecture, applicable on parallel channels in each layer. The key motivation is that not all feature channels are necessary for learning, and often the latent space contains empty features. The pruning method regularizes the channels in such a way that each higher channel output will have a higher penalty. This ensures that the model will try to reduce the unnecessary channels to zero output. During inference, a smaller model can be distilled, containing only the non-zero parts of the parent model.
            <img src="figs/pruning.png" alt="Proposed pruning method">
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results and Discussion</h2>
        <div class="content has-text-justified">
          <p>
            The key goal is to retain object detection performance across different driving scenes while reducing the frame-by-frame computation as much as possible. In this regard, we will look at the performance vs computation graphs at the end of the project. Hypothetically, performance vs computation graph should have and upward trend. Our key aim is to reduce the slope of the curve as much as possible - meaning that model computation can be drastically reduced without much loss in performance. Some of the key metrics for performance in 3D object detection are: 2D average precision (AP), birds eye view (BEV) AP, 3D AP. And for the model computation, we will take the MACs/FLOPs of the architecture during inference.          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Literature Review -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">References</h2>
        <div class="content has-text-justified">
          <ol>
          <li>
              Lang, Alex H., et al. "Pointpillars: Fast encoders for object detection from point clouds." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.
          </li>
          <li>
              Yu, Chenglin, et al. "Structured Pruning Learns Compact and Accurate Models." <em>arXiv</em>, 2022.
          </li>
          <li>
              Wang, Jiaxiang, et al. "Structured Pruning for Deep Convolutional Neural Networks: A Survey." <em>arXiv</em>, 2023.
          </li>
          <li>
              Yeh, Chih-Kuan, et al. "Deep Trim: Revisiting L1 Regularization for Connection Pruning of Deep Networks." <em>Papers with Code</em>, 2019.
          </li>
          <li>
              Wang, Jiaxiang, et al. "Neural Pruning via Growing Regularization." <em>arXiv</em>, 2020.
          </li>
          <li>
              Yu, Ritchie, et al. "NISP: Pruning Networks Using Neuron Importance Score Propagation." <em>arXiv</em>, 2017.
          </li>
          <li>
              Molchanov, Pavlo, et al. "Importance Estimation for Neural Network Pruning." <em>arXiv</em>, 2019.
          </li>
          <li>
              Sunil, Vadera, and Salem Ameen. "Methods for Pruning Deep Neural Networks." <em>arXiv</em>, 2020.
          </li>
          <li>
              Liu, Zhuang, et al. "Rethinking the Value of Network Pruning." <em>arXiv</em>, 2019.
          </li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->








  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            </a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
