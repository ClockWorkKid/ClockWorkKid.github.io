<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Latent Pruning for Compute Optimization in 3D Object Detection Frameworks</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Latent Pruning for Compute Optimization in 3D Object Detection Frameworks</h1>


          
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Mir Sayeed Mohammad</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Mizanur Rahaman Nayan</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Sujoy Mondal</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Uday Kamal</a>
                  </span>
                  </div>  
     
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Georgia Institute of Technology<br>CS 7641</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Our work aims to reduce the computation in a deep neural network model deployed in 3D object detection task by removing channels in different model layers and optimizing inference. Structured pruning methods, such as CoFi, combine coarse and fine-grained units with layer-wise distillation to enhance model compression and inference speed without significant accuracy loss (Yu et al.; Wang et al.). Layer and head pruning in Transformer models also effectively reduce model size while maintaining performance (Yu et al.). Regularization-based pruning methods like L1 regularization and growing regularization gradually drive unimportant weights to zero before pruning, balancing parameter reduction and accuracy (Yeh et al.; Wang et al., "Neural Pruning via Growing Regularization"). Importance-based pruning uses criteria like neuron importance score propagation (NISP) and Taylor expansion-based methods to iteratively prune less important neurons, retaining essential features and performance (Yu et al.; Molchanov et al.; Sunil and Salem; Liu et al.). These techniques collectively improve the efficiency and performance of neural networks by systematically reducing their complexity.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Problem Definition</h2>
        <div class="content has-text-justified">
          <p>
           	LIDAR scanners are crucial components in autonomous systems, providing point cloud data that is integral for perceiving surroundings. However, processing this unstructured data in object detection frameworks involves significant computational overhead. Current methods, like the PointPillars (Lang, Alex H., et al.) architecture, convert point clouds into a structured format resembling voxels, leading to computational redundancy due to sparse data representation.
Efficient processing of LIDAR data is essential for real-time applications like autonomous driving. The majority of computation in object detection frameworks occurs during the conversion of voxelized data in the feature extraction stage. This bottleneck necessitates optimization to enhance computational efficiency without compromising detection accuracy. Current approaches, such as Matryoshka Representation Learning, offer promising avenues by selectively pruning feature channels, thereby reducing computational load while maintaining acceptable detection performance levels.
This project aims to explore and optimize the integration of network pruning techniques within the PointPillars framework. By leveraging adaptive latent regularization, we seek to significantly reduce computation and memory requirements while evaluating its impact on detection accuracy across different scenes and object classes. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methods</h2>
        <div class="content has-text-justified">
          <p>Pointcloud data, representing a framewise stream of LASER-reflected points in the Cartesian coordinate system, is converted to a grid structure called voxels for object detection. In the PointPillars architecture, points within a field of view are grouped into pillars in the x-y plane. Each pillar is augmented to contain a fixed number of points, which then pass through an invariant dense layer to generate features. These features form 2D pseudo images. During preprocessing and pillar encoding, noise is added to account for sensor uncertainty, and data augmentation methods like rotation and flipping are applied.
          </p> <p>
            Widely used algorithms in object detection frameworks include anchor generation, bounding box encoding, and non-max suppression of candidate bounding boxes. Models such as PointNet, PointNet++, PV-RCNN, VoxelNet, and F-ConvNet are utilized for 3D object detection. A typical object detection pipeline comprises modules like the encoder, backbone, and model head. The dense backbone handles feature processing and accounts for most of the model's computation. Our goal is to develop a model-agnostic learning approach, ensuring that the pruning method can be applied to all convolution/dense layer-based neural network architectures.
            <figure><img src="fig/pointpillars.png" alt="PointPillars architecture">
              <figcaption>PointPillars architecture</figcaption>
            </figure>
          </p><p>
            Our work focuses on optimizing model architecture by pruning parallel channels in each layer. The motivation is that not all feature channels are necessary for learning, and the latent space often contains redundant features. The pruning method regularizes channels so that higher channel outputs incur higher penalties, encouraging the model to minimize unnecessary channels to zero output. During inference, a distilled smaller model retains only the non-zero parts of the parent model, improving efficiency. This approach ensures the model remains effective while reducing computational requirements by eliminating redundant channels.
            <figure>
            <img src="fig/pruning.png" alt="Proposed pruning method">
            <figcaption>Proposed pruning method</figcaption>
          </figure>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results and Discussion</h2>
        <div class="content has-text-justified">
          <p>
            The key goal is to retain object detection performance across different driving scenes while reducing the frame-by-frame computation as much as possible. In this regard, we will look at the performance vs computation graphs at the end of the project. Hypothetically, performance vs computation graph should have and upward trend. Our key aim is to reduce the slope of the curve as much as possible - meaning that model computation can be drastically reduced without much loss in performance. Some of the key metrics for performance in 3D object detection are: 2D average precision (AP), birds eye view (BEV) AP, 3D AP. And for the model computation, we will take the MACs/FLOPs of the architecture during inference.          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Literature Review -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">References</h2>
        <div class="content has-text-justified">
          <ol>
          <li>
              Lang, Alex H., et al. "Pointpillars: Fast encoders for object detection from point clouds." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.
          </li>
          <li>
              Yu, Chenglin, et al. "Structured Pruning Learns Compact and Accurate Models." <em>arXiv</em>, 2022.
          </li>
          <li>
              Wang, Jiaxiang, et al. "Structured Pruning for Deep Convolutional Neural Networks: A Survey." <em>arXiv</em>, 2023.
          </li>
          <li>
              Yeh, Chih-Kuan, et al. "Deep Trim: Revisiting L1 Regularization for Connection Pruning of Deep Networks." <em>Papers with Code</em>, 2019.
          </li>
          <li>
              Wang, Jiaxiang, et al. "Neural Pruning via Growing Regularization." <em>arXiv</em>, 2020.
          </li>
          <li>
              Yu, Ritchie, et al. "NISP: Pruning Networks Using Neuron Importance Score Propagation." <em>arXiv</em>, 2017.
          </li>
          <li>
              Molchanov, Pavlo, et al. "Importance Estimation for Neural Network Pruning." <em>arXiv</em>, 2019.
          </li>
          <li>
              Sunil, Vadera, and Salem Ameen. "Methods for Pruning Deep Neural Networks." <em>arXiv</em>, 2020.
          </li>
          <li>
              Liu, Zhuang, et al. "Rethinking the Value of Network Pruning." <em>arXiv</em>, 2019.
          </li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->








  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            </a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
