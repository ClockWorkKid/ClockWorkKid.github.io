{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import setup_seed, keep_bbox_from_image_range, \\\n",
    "    keep_bbox_from_lidar_range, write_pickle, write_label, \\\n",
    "    iou2d, iou3d_camera, iou_bev\n",
    "from dataset import Kitti, get_dataloader\n",
    "from model import PointPillars\n",
    "from loss import Loss\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_thresholds(tp_scores, total_num_valid_gt, num_sample_pts=41):\n",
    "    score_thresholds = []\n",
    "    tp_scores = sorted(tp_scores)[::-1]\n",
    "    cur_recall, pts_ind = 0, 0\n",
    "    for i, score in enumerate(tp_scores):\n",
    "        lrecall = (i + 1) / total_num_valid_gt\n",
    "        rrecall = (i + 2) / total_num_valid_gt\n",
    "\n",
    "        if i == len(tp_scores) - 1:\n",
    "            score_thresholds.append(score)\n",
    "            break\n",
    "\n",
    "        if (lrecall + rrecall) / 2 < cur_recall:\n",
    "            continue\n",
    "\n",
    "        score_thresholds.append(score)\n",
    "        pts_ind += 1\n",
    "        cur_recall = pts_ind / (num_sample_pts - 1)\n",
    "    return score_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_eval(det_results, gt_results, CLASSES, saved_path):\n",
    "    '''\n",
    "    det_results: list,\n",
    "    gt_results: dict(id -> det_results)\n",
    "    CLASSES: dict\n",
    "    '''\n",
    "    assert len(det_results) == len(gt_results)\n",
    "    f = open(os.path.join(saved_path, 'eval_results.txt'), 'w')\n",
    "\n",
    "    # 1. calculate iou\n",
    "    ious = {\n",
    "        'bbox_2d': [],\n",
    "        'bbox_bev': [],\n",
    "        'bbox_3d': []\n",
    "    }\n",
    "    ids = list(sorted(gt_results.keys()))\n",
    "    for id in ids:\n",
    "        gt_result = gt_results[id]['annos']\n",
    "        det_result = det_results[id]\n",
    "\n",
    "        # 1.1, 2d bboxes iou\n",
    "        gt_bboxes2d = gt_result['bbox'].astype(np.float32)\n",
    "        det_bboxes2d = det_result['bbox'].astype(np.float32)\n",
    "        iou2d_v = iou2d(torch.from_numpy(gt_bboxes2d).cuda(), torch.from_numpy(det_bboxes2d).cuda())\n",
    "        ious['bbox_2d'].append(iou2d_v.cpu().numpy())\n",
    "\n",
    "        # 1.2, bev iou\n",
    "        gt_location = gt_result['location'].astype(np.float32)\n",
    "        gt_dimensions = gt_result['dimensions'].astype(np.float32)\n",
    "        gt_rotation_y = gt_result['rotation_y'].astype(np.float32)\n",
    "        det_location = det_result['location'].astype(np.float32)\n",
    "        det_dimensions = det_result['dimensions'].astype(np.float32)\n",
    "        det_rotation_y = det_result['rotation_y'].astype(np.float32)\n",
    "\n",
    "        gt_bev = np.concatenate([gt_location[:, [0, 2]], gt_dimensions[:, [0, 2]], gt_rotation_y[:, None]], axis=-1)\n",
    "        det_bev = np.concatenate([det_location[:, [0, 2]], det_dimensions[:, [0, 2]], det_rotation_y[:, None]], axis=-1)\n",
    "        iou_bev_v = iou_bev(torch.from_numpy(gt_bev).cuda(), torch.from_numpy(det_bev).cuda())\n",
    "        ious['bbox_bev'].append(iou_bev_v.cpu().numpy())\n",
    "\n",
    "        # 1.3, 3dbboxes iou\n",
    "        gt_bboxes3d = np.concatenate([gt_location, gt_dimensions, gt_rotation_y[:, None]], axis=-1)\n",
    "        det_bboxes3d = np.concatenate([det_location, det_dimensions, det_rotation_y[:, None]], axis=-1)\n",
    "        iou3d_v = iou3d_camera(torch.from_numpy(gt_bboxes3d).cuda(), torch.from_numpy(det_bboxes3d).cuda())\n",
    "        ious['bbox_3d'].append(iou3d_v.cpu().numpy())\n",
    "\n",
    "    MIN_IOUS = {\n",
    "        'Pedestrian': [0.5, 0.5, 0.5],\n",
    "        'Cyclist': [0.5, 0.5, 0.5],\n",
    "        'Car': [0.7, 0.7, 0.7]\n",
    "    }\n",
    "    MIN_HEIGHT = [40, 25, 25]\n",
    "\n",
    "    overall_results = {}\n",
    "    for e_ind, eval_type in enumerate(['bbox_2d', 'bbox_bev', 'bbox_3d']):\n",
    "        eval_ious = ious[eval_type]\n",
    "        eval_ap_results, eval_aos_results = {}, {}\n",
    "        for cls in CLASSES:\n",
    "            eval_ap_results[cls] = []\n",
    "            eval_aos_results[cls] = []\n",
    "            CLS_MIN_IOU = MIN_IOUS[cls][e_ind]\n",
    "            for difficulty in [0, 1, 2]:\n",
    "                # 1. bbox property\n",
    "                total_gt_ignores, total_det_ignores, total_dc_bboxes, total_scores = [], [], [], []\n",
    "                total_gt_alpha, total_det_alpha = [], []\n",
    "                for id in ids:\n",
    "                    gt_result = gt_results[id]['annos']\n",
    "                    det_result = det_results[id]\n",
    "\n",
    "                    # 1.1 gt bbox property\n",
    "                    cur_gt_names = gt_result['name']\n",
    "                    cur_difficulty = gt_result['difficulty']\n",
    "                    gt_ignores, dc_bboxes = [], []\n",
    "                    for j, cur_gt_name in enumerate(cur_gt_names):\n",
    "                        ignore = cur_difficulty[j] < 0 or cur_difficulty[j] > difficulty\n",
    "                        if cur_gt_name == cls:\n",
    "                            valid_class = 1\n",
    "                        elif cls == 'Pedestrian' and cur_gt_name == 'Person_sitting':\n",
    "                            valid_class = 0\n",
    "                        elif cls == 'Car' and cur_gt_name == 'Van':\n",
    "                            valid_class = 0\n",
    "                        else:\n",
    "                            valid_class = -1\n",
    "                        \n",
    "                        if valid_class == 1 and not ignore:\n",
    "                            gt_ignores.append(0)\n",
    "                        elif valid_class == 0 or (valid_class == 1 and ignore):\n",
    "                            gt_ignores.append(1)\n",
    "                        else:\n",
    "                            gt_ignores.append(-1)\n",
    "                        \n",
    "                        if cur_gt_name == 'DontCare':\n",
    "                            dc_bboxes.append(gt_result['bbox'][j])\n",
    "                    total_gt_ignores.append(gt_ignores)\n",
    "                    total_dc_bboxes.append(np.array(dc_bboxes))\n",
    "                    total_gt_alpha.append(gt_result['alpha'])\n",
    "\n",
    "                    # 1.2 det bbox property\n",
    "                    cur_det_names = det_result['name']\n",
    "                    cur_det_heights = det_result['bbox'][:, 3] - det_result['bbox'][:, 1]\n",
    "                    det_ignores = []\n",
    "                    for j, cur_det_name in enumerate(cur_det_names):\n",
    "                        if cur_det_heights[j] < MIN_HEIGHT[difficulty]:\n",
    "                            det_ignores.append(1)\n",
    "                        elif cur_det_name == cls:\n",
    "                            det_ignores.append(0)\n",
    "                        else:\n",
    "                            det_ignores.append(-1)\n",
    "                    total_det_ignores.append(det_ignores)\n",
    "                    total_scores.append(det_result['score'])\n",
    "                    total_det_alpha.append(det_result['alpha'])\n",
    "\n",
    "                # 2. calculate scores thresholds for PR curve\n",
    "                tp_scores = []\n",
    "                for i, id in enumerate(ids):\n",
    "                    cur_eval_ious = eval_ious[i]\n",
    "                    gt_ignores, det_ignores = total_gt_ignores[i], total_det_ignores[i]\n",
    "                    scores = total_scores[i]\n",
    "\n",
    "                    nn, mm = cur_eval_ious.shape\n",
    "                    assigned = np.zeros((mm, ), dtype=np.bool_)\n",
    "                    for j in range(nn):\n",
    "                        if gt_ignores[j] == -1:\n",
    "                            continue\n",
    "                        match_id, match_score = -1, -1\n",
    "                        for k in range(mm):\n",
    "                            if not assigned[k] and det_ignores[k] >= 0 and cur_eval_ious[j, k] > CLS_MIN_IOU and scores[k] > match_score:\n",
    "                                match_id = k\n",
    "                                match_score = scores[k]\n",
    "                        if match_id != -1:\n",
    "                            assigned[match_id] = True\n",
    "                            if det_ignores[match_id] == 0 and gt_ignores[j] == 0:\n",
    "                                tp_scores.append(match_score)\n",
    "                total_num_valid_gt = np.sum([np.sum(np.array(gt_ignores) == 0) for gt_ignores in total_gt_ignores])\n",
    "                score_thresholds = get_score_thresholds(tp_scores, total_num_valid_gt)    \n",
    "            \n",
    "                # 3. draw PR curve and calculate mAP\n",
    "                tps, fns, fps, total_aos = [], [], [], []\n",
    "\n",
    "                for score_threshold in score_thresholds:\n",
    "                    tp, fn, fp = 0, 0, 0\n",
    "                    aos = 0\n",
    "                    for i, id in enumerate(ids):\n",
    "                        cur_eval_ious = eval_ious[i]\n",
    "                        gt_ignores, det_ignores = total_gt_ignores[i], total_det_ignores[i]\n",
    "                        gt_alpha, det_alpha = total_gt_alpha[i], total_det_alpha[i]\n",
    "                        scores = total_scores[i]\n",
    "\n",
    "                        nn, mm = cur_eval_ious.shape\n",
    "                        assigned = np.zeros((mm, ), dtype=np.bool_)\n",
    "                        for j in range(nn):\n",
    "                            if gt_ignores[j] == -1:\n",
    "                                continue\n",
    "                            match_id, match_iou = -1, -1\n",
    "                            for k in range(mm):\n",
    "                                if not assigned[k] and det_ignores[k] >= 0 and scores[k] >= score_threshold and cur_eval_ious[j, k] > CLS_MIN_IOU:\n",
    "    \n",
    "                                    if det_ignores[k] == 0 and cur_eval_ious[j, k] > match_iou:\n",
    "                                        match_iou = cur_eval_ious[j, k]\n",
    "                                        match_id = k\n",
    "                                    elif det_ignores[k] == 1 and match_iou == -1:\n",
    "                                        match_id = k\n",
    "\n",
    "                            if match_id != -1:\n",
    "                                assigned[match_id] = True\n",
    "                                if det_ignores[match_id] == 0 and gt_ignores[j] == 0:\n",
    "                                    tp += 1\n",
    "                                    if eval_type == 'bbox_2d':\n",
    "                                        aos += (1 + np.cos(gt_alpha[j] - det_alpha[match_id])) / 2\n",
    "                            else:\n",
    "                                if gt_ignores[j] == 0:\n",
    "                                    fn += 1\n",
    "                            \n",
    "                        for k in range(mm):\n",
    "                            if det_ignores[k] == 0 and scores[k] >= score_threshold and not assigned[k]:\n",
    "                                fp += 1\n",
    "                        \n",
    "                        # In case 2d bbox evaluation, we should consider dontcare bboxes\n",
    "                        if eval_type == 'bbox_2d':\n",
    "                            dc_bboxes = total_dc_bboxes[i]\n",
    "                            det_bboxes = det_results[id]['bbox']\n",
    "                            if len(dc_bboxes) > 0:\n",
    "                                ious_dc_det = iou2d(torch.from_numpy(det_bboxes), torch.from_numpy(dc_bboxes), metric=1).numpy().T\n",
    "                                for j in range(len(dc_bboxes)):\n",
    "                                    for k in range(len(det_bboxes)):\n",
    "                                        if det_ignores[k] == 0 and scores[k] >= score_threshold and not assigned[k]:\n",
    "                                            if ious_dc_det[j, k] > CLS_MIN_IOU:\n",
    "                                                fp -= 1\n",
    "                                                assigned[k] = True\n",
    "                            \n",
    "                    tps.append(tp)\n",
    "                    fns.append(fn)\n",
    "                    fps.append(fp)\n",
    "                    if eval_type == 'bbox_2d':\n",
    "                        total_aos.append(aos)\n",
    "\n",
    "                tps, fns, fps = np.array(tps), np.array(fns), np.array(fps)\n",
    "\n",
    "                precisions = tps / (tps + fns) # actually this is recalls\n",
    "                # precisions = tps / (tps + fps)\n",
    "                for i in range(len(score_thresholds)):\n",
    "                    precisions[i] = np.max(precisions[i:])\n",
    "                \n",
    "                sums_AP = 0\n",
    "                for i in range(0, len(score_thresholds), 4):\n",
    "                    sums_AP += precisions[i]\n",
    "                mAP = sums_AP / 11 * 100\n",
    "                eval_ap_results[cls].append(mAP)\n",
    "\n",
    "                if eval_type == 'bbox_2d':\n",
    "                    total_aos = np.array(total_aos)\n",
    "                    similarity = total_aos / (tps + fps)\n",
    "                    for i in range(len(score_thresholds)):\n",
    "                        similarity[i] = np.max(similarity[i:])\n",
    "                    sums_similarity = 0\n",
    "                    for i in range(0, len(score_thresholds), 4):\n",
    "                        sums_similarity += similarity[i]\n",
    "                    mSimilarity = sums_similarity / 11 * 100\n",
    "                    eval_aos_results[cls].append(mSimilarity)\n",
    "\n",
    "        print(f'=========={eval_type.upper()}==========')\n",
    "        print(f'=========={eval_type.upper()}==========', file=f)\n",
    "        for k, v in eval_ap_results.items():\n",
    "            print(f'{k} AP@{MIN_IOUS[k][e_ind]}: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}')\n",
    "            print(f'{k} AP@{MIN_IOUS[k][e_ind]}: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}', file=f)\n",
    "        if eval_type == 'bbox_2d':\n",
    "            print(f'==========AOS==========')\n",
    "            print(f'==========AOS==========', file=f)\n",
    "            for k, v in eval_aos_results.items():\n",
    "                print(f'{k} AOS@{MIN_IOUS[k][e_ind]}: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}')\n",
    "                print(f'{k} AOS@{MIN_IOUS[k][e_ind]}: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}', file=f)\n",
    "        \n",
    "        overall_results[eval_type] = np.mean(list(eval_ap_results.values()), 0)\n",
    "        if eval_type == 'bbox_2d':\n",
    "            overall_results['AOS'] = np.mean(list(eval_aos_results.values()), 0)\n",
    "    \n",
    "    print(f'\\n==========Overall==========')\n",
    "    print(f'\\n==========Overall==========', file=f)\n",
    "    for k, v in overall_results.items():\n",
    "        print(f'{k} AP: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}')\n",
    "        print(f'{k} AP: {v[0]:.4f} {v[1]:.4f} {v[2]:.4f}', file=f)\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.data_root = \"dataset/KITTI\"\n",
    "        self.ckpt = \"logs/pillar_sequence_memory_gating_logloss/checkpoints/epoch_160.pth\"\n",
    "        self.saved_path = \"logs/pillar_sequence_memory_gating_logloss/results\"\n",
    "        self.batch_size = 1\n",
    "        self.num_workers = 4\n",
    "        self.nclasses = 3\n",
    "        self.no_cuda = not torch.cuda.is_available()\n",
    "\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Kitti(data_root=args.data_root,\n",
    "                    split='val')\n",
    "val_dataloader = get_dataloader(dataset=val_dataset, \n",
    "                                batch_size=args.batch_size, \n",
    "                                num_workers=args.num_workers,\n",
    "                                shuffle=False)\n",
    "CLASSES = Kitti.CLASSES\n",
    "LABEL2CLASSES = {v:k for k, v in CLASSES.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointPillars(\n",
       "  (pillar_layer): PillarLayer(\n",
       "    (voxel_layer): Voxelization(voxel_size=[0.16, 0.16, 4], point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1], max_num_points=32, max_voxels=(16000, 40000), deterministic=True)\n",
       "  )\n",
       "  (pillar_encoder): PillarEncoder(\n",
       "    (conv): Conv1d(9, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (bn): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (gate0): Gate(\n",
       "    (conv1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (gate1): Gate(\n",
       "    (conv1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (gate2): Gate(\n",
       "    (conv1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (gate3): Gate(\n",
       "    (conv1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (gate4): Gate(\n",
       "    (conv1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (gate5): Gate(\n",
       "    (conv1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (gate6): Gate(\n",
       "    (conv1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (gate7): Gate(\n",
       "    (conv1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (backbone0): Backbone(\n",
       "    (multi_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(64, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone1): Backbone(\n",
       "    (multi_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(64, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone2): Backbone(\n",
       "    (multi_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(64, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone3): Backbone(\n",
       "    (multi_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(64, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone4): Backbone(\n",
       "    (multi_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(64, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone5): Backbone(\n",
       "    (multi_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(64, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone6): Backbone(\n",
       "    (multi_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(64, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone7): Backbone(\n",
       "    (multi_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(64, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck0): Neck(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck1): Neck(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck2): Neck(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck3): Neck(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck4): Neck(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck5): Neck(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck6): Neck(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck7): Neck(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Head(\n",
       "    (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_reg): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not args.no_cuda:\n",
    "    model = PointPillars(nclasses=args.nclasses).cuda()\n",
    "    model.load_state_dict(torch.load(args.ckpt))\n",
    "else:\n",
    "    model = PointPillars(nclasses=args.nclasses)\n",
    "    model.load_state_dict(\n",
    "        torch.load(args.ckpt, map_location=torch.device('cpu')))\n",
    "    \n",
    "\n",
    "\n",
    "saved_path = args.saved_path\n",
    "os.makedirs(saved_path, exist_ok=True)\n",
    "saved_submit_path = os.path.join(saved_path, 'submit')\n",
    "os.makedirs(saved_submit_path, exist_ok=True)\n",
    "\n",
    "pcd_limit_range = np.array([0, -40, -3, 70.4, 40, 0.0], dtype=np.float32)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting and Formatting the results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2879 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sayeed/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541702/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|| 2879/2879 [04:35<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23032\n",
      "tensor(20153, device='cuda:0')\n",
      "Evaluating.. Please wait several seconds.\n",
      "==========BBOX_2D==========\n",
      "Pedestrian AP@0.5: 55.4703 52.8956 50.9357\n",
      "Cyclist AP@0.5: 99.1886 84.0851 81.4598\n",
      "Car AP@0.7: 84.5046 71.1800 67.5895\n",
      "==========AOS==========\n",
      "Pedestrian AOS@0.5: 47.5685 46.7146 45.4635\n",
      "Cyclist AOS@0.5: 77.3289 63.2157 61.2804\n",
      "Car AOS@0.7: 84.3903 77.6703 76.4459\n",
      "==========BBOX_BEV==========\n",
      "Pedestrian AP@0.5: 63.9996 54.4097 52.0281\n",
      "Cyclist AP@0.5: 97.9716 71.6169 68.6217\n",
      "Car AP@0.7: 83.2078 69.0645 65.2654\n",
      "==========BBOX_3D==========\n",
      "Pedestrian AP@0.5: 53.5138 51.1675 42.5835\n",
      "Cyclist AP@0.5: 86.1147 65.2672 55.6099\n",
      "Car AP@0.7: 57.1114 43.2868 39.8667\n",
      "\n",
      "==========Overall==========\n",
      "bbox_2d AP: 79.7212 69.3869 66.6616\n",
      "AOS AP: 69.7626 62.5335 61.0633\n",
      "bbox_bev AP: 81.7263 65.0304 61.9717\n",
      "bbox_3d AP: 65.5800 53.2405 46.0200\n"
     ]
    }
   ],
   "source": [
    "val_epoch_compute = 0\n",
    "val_epoch_g_probability = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    format_results = {}\n",
    "    print('Predicting and Formatting the results.')\n",
    "    for i, data_dict in enumerate(tqdm(val_dataloader)):\n",
    "        if not args.no_cuda:\n",
    "            # move the tensors to the cuda\n",
    "            for key in data_dict:\n",
    "                for j, item in enumerate(data_dict[key]):\n",
    "                    if torch.is_tensor(item):\n",
    "                        data_dict[key][j] = data_dict[key][j].cuda()\n",
    "        \n",
    "        batched_pts = data_dict['batched_pts']\n",
    "        batched_pts0 = data_dict['batched_pts0']\n",
    "        batched_gt_bboxes = data_dict['batched_gt_bboxes']\n",
    "        batched_labels = data_dict['batched_labels']\n",
    "        batched_difficulty = data_dict['batched_difficulty']\n",
    "        batch_results0, f = model(batched_pts=batched_pts,\n",
    "                               batched_pts0=batched_pts0, \n",
    "                                mode='val',\n",
    "                                batched_gt_bboxes=batched_gt_bboxes, \n",
    "                                batched_gt_labels=batched_labels)\n",
    "        # pdb.set_trace()\n",
    "        val_epoch_compute = val_epoch_compute + f.shape[0]*f.shape[1]\n",
    "        val_epoch_g_probability = val_epoch_g_probability + torch.sum(f>0.5)\n",
    "\n",
    "        for j, result in enumerate(batch_results0):\n",
    "            format_result = {\n",
    "                'name': [],\n",
    "                'truncated': [],\n",
    "                'occluded': [],\n",
    "                'alpha': [],\n",
    "                'bbox': [],\n",
    "                'dimensions': [],\n",
    "                'location': [],\n",
    "                'rotation_y': [],\n",
    "                'score': []\n",
    "            }\n",
    "            \n",
    "            calib_info = data_dict['batched_calib_info'][j]\n",
    "            tr_velo_to_cam = calib_info['Tr_velo_to_cam'].astype(np.float32)\n",
    "            r0_rect = calib_info['R0_rect'].astype(np.float32)\n",
    "            P2 = calib_info['P2'].astype(np.float32)\n",
    "            image_shape = data_dict['batched_img_info'][j]['image_shape']\n",
    "            idx = data_dict['batched_img_info'][j]['image_idx']\n",
    "            result_filter = keep_bbox_from_image_range(result, tr_velo_to_cam, r0_rect, P2, image_shape)\n",
    "            result_filter = keep_bbox_from_lidar_range(result_filter, pcd_limit_range)\n",
    "\n",
    "            lidar_bboxes = result_filter['lidar_bboxes']\n",
    "            labels, scores = result_filter['labels'], result_filter['scores']\n",
    "            bboxes2d, camera_bboxes = result_filter['bboxes2d'], result_filter['camera_bboxes']\n",
    "            for lidar_bbox, label, score, bbox2d, camera_bbox in \\\n",
    "                zip(lidar_bboxes, labels, scores, bboxes2d, camera_bboxes):\n",
    "                format_result['name'].append(LABEL2CLASSES[label])\n",
    "                format_result['truncated'].append(0.0)\n",
    "                format_result['occluded'].append(0)\n",
    "                alpha = camera_bbox[6] - np.arctan2(camera_bbox[0], camera_bbox[2])\n",
    "                format_result['alpha'].append(alpha)\n",
    "                format_result['bbox'].append(bbox2d)\n",
    "                format_result['dimensions'].append(camera_bbox[3:6])\n",
    "                format_result['location'].append(camera_bbox[:3])\n",
    "                format_result['rotation_y'].append(camera_bbox[6])\n",
    "                format_result['score'].append(score)\n",
    "            \n",
    "            write_label(format_result, os.path.join(saved_submit_path, f'{idx:06d}.txt'))\n",
    "\n",
    "            format_results[idx] = {k:np.array(v) for k, v in format_result.items()}\n",
    "    \n",
    "    write_pickle(format_results, os.path.join(saved_path, 'results.pkl'))\n",
    "\n",
    "print(val_epoch_compute)\n",
    "print(val_epoch_g_probability)\n",
    "print('Evaluating.. Please wait several seconds.')\n",
    "do_eval(format_results, val_dataset.data_infos, CLASSES, saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     format_results = {}\n",
    "#     print('Predicting and Formatting the results.')\n",
    "#     for i, data_dict in enumerate(tqdm(val_dataloader)):\n",
    "#         if not args.no_cuda:\n",
    "#             # move the tensors to the cuda\n",
    "#             for key in data_dict:\n",
    "#                 for j, item in enumerate(data_dict[key]):\n",
    "#                     if torch.is_tensor(item):\n",
    "#                         data_dict[key][j] = data_dict[key][j].cuda()\n",
    "        \n",
    "#         batched_pts = data_dict['batched_pts']\n",
    "#         batched_gt_bboxes = data_dict['batched_gt_bboxes']\n",
    "#         batched_labels = data_dict['batched_labels']\n",
    "#         batched_difficulty = data_dict['batched_difficulty']\n",
    "#         batch_results0, batch_results1, batch_results2 = model(batched_pts=batched_pts, \n",
    "#                                 mode='val',\n",
    "#                                 batched_gt_bboxes=batched_gt_bboxes, \n",
    "#                                 batched_gt_labels=batched_labels)\n",
    "#         # pdb.set_trace()\n",
    "\n",
    "#         for j, result in enumerate(batch_results2):\n",
    "#             format_result = {\n",
    "#                 'name': [],\n",
    "#                 'truncated': [],\n",
    "#                 'occluded': [],\n",
    "#                 'alpha': [],\n",
    "#                 'bbox': [],\n",
    "#                 'dimensions': [],\n",
    "#                 'location': [],\n",
    "#                 'rotation_y': [],\n",
    "#                 'score': []\n",
    "#             }\n",
    "            \n",
    "#             calib_info = data_dict['batched_calib_info'][j]\n",
    "#             tr_velo_to_cam = calib_info['Tr_velo_to_cam'].astype(np.float32)\n",
    "#             r0_rect = calib_info['R0_rect'].astype(np.float32)\n",
    "#             P2 = calib_info['P2'].astype(np.float32)\n",
    "#             image_shape = data_dict['batched_img_info'][j]['image_shape']\n",
    "#             idx = data_dict['batched_img_info'][j]['image_idx']\n",
    "#             result_filter = keep_bbox_from_image_range(result, tr_velo_to_cam, r0_rect, P2, image_shape)\n",
    "#             result_filter = keep_bbox_from_lidar_range(result_filter, pcd_limit_range)\n",
    "\n",
    "#             lidar_bboxes = result_filter['lidar_bboxes']\n",
    "#             labels, scores = result_filter['labels'], result_filter['scores']\n",
    "#             bboxes2d, camera_bboxes = result_filter['bboxes2d'], result_filter['camera_bboxes']\n",
    "#             for lidar_bbox, label, score, bbox2d, camera_bbox in \\\n",
    "#                 zip(lidar_bboxes, labels, scores, bboxes2d, camera_bboxes):\n",
    "#                 format_result['name'].append(LABEL2CLASSES[label])\n",
    "#                 format_result['truncated'].append(0.0)\n",
    "#                 format_result['occluded'].append(0)\n",
    "#                 alpha = camera_bbox[6] - np.arctan2(camera_bbox[0], camera_bbox[2])\n",
    "#                 format_result['alpha'].append(alpha)\n",
    "#                 format_result['bbox'].append(bbox2d)\n",
    "#                 format_result['dimensions'].append(camera_bbox[3:6])\n",
    "#                 format_result['location'].append(camera_bbox[:3])\n",
    "#                 format_result['rotation_y'].append(camera_bbox[6])\n",
    "#                 format_result['score'].append(score)\n",
    "            \n",
    "#             write_label(format_result, os.path.join(saved_submit_path, f'{idx:06d}.txt'))\n",
    "\n",
    "#             format_results[idx] = {k:np.array(v) for k, v in format_result.items()}\n",
    "    \n",
    "#     write_pickle(format_results, os.path.join(saved_path, 'results.pkl'))\n",
    "\n",
    "# print('Evaluating.. Please wait several seconds.')\n",
    "# do_eval(format_results, val_dataset.data_infos, CLASSES, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pdb\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "from utils import setup_seed, read_points, read_calib, read_label, \\\n",
    "    keep_bbox_from_image_range, keep_bbox_from_lidar_range, vis_pc, \\\n",
    "    vis_img_3d, bbox3d2corners_camera, points_camera2image, \\\n",
    "    bbox_camera2lidar\n",
    "from model import PointPillars\n",
    "\n",
    "\n",
    "\n",
    "def point_range_filter(pts, point_range=[0, -39.68, -3, 69.12, 39.68, 1]):\n",
    "    '''\n",
    "    data_dict: dict(pts, gt_bboxes_3d, gt_labels, gt_names, difficulty)\n",
    "    point_range: [x1, y1, z1, x2, y2, z2]\n",
    "    '''\n",
    "    flag_x_low = pts[:, 0] > point_range[0]\n",
    "    flag_y_low = pts[:, 1] > point_range[1]\n",
    "    flag_z_low = pts[:, 2] > point_range[2]\n",
    "    flag_x_high = pts[:, 0] < point_range[3]\n",
    "    flag_y_high = pts[:, 1] < point_range[4]\n",
    "    flag_z_high = pts[:, 2] < point_range[5]\n",
    "    keep_mask = flag_x_low & flag_y_low & flag_z_low & flag_x_high & flag_y_high & flag_z_high\n",
    "    pts = pts[keep_mask]\n",
    "    return pts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestArgs:\n",
    "    def __init__(self, fileName):\n",
    "        self.data_root = \"dataset/KITTI\"\n",
    "        self.ckpt = \"logs/pillar_sequence_memory/checkpoints/epoch_160.pth\"\n",
    "        self.pc_path = self.data_root + \"/training/velodyne/\" + fileName + \".bin\"\n",
    "        self.calib_path = self.data_root + \"/training/calib/\" + fileName + \".txt\"\n",
    "        self.img_path = self.data_root + \"/training/image_2/\" + fileName + \".png\"\n",
    "        self.gt_path = self.data_root + \"/training/label_2/\" + fileName + \".txt\"\n",
    "        self.no_cuda = not torch.cuda.is_available()\n",
    "\n",
    "args = TestArgs(\"0000_000020\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = {\n",
    "    'Pedestrian': 0, \n",
    "    'Cyclist': 1, \n",
    "    'Car': 2\n",
    "    }\n",
    "LABEL2CLASSES = {v:k for k, v in CLASSES.items()}\n",
    "pcd_limit_range = np.array([0, -40, -3, 70.4, 40, 0.0], dtype=np.float32)\n",
    "\n",
    "if not args.no_cuda:\n",
    "    model = PointPillars(nclasses=len(CLASSES)).cuda()\n",
    "    model.load_state_dict(torch.load(args.ckpt))\n",
    "else:\n",
    "    model = PointPillars(nclasses=len(CLASSES))\n",
    "    model.load_state_dict(\n",
    "        torch.load(args.ckpt, map_location=torch.device('cpu')))\n",
    "    \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the file\n",
    "\n",
    "output_destination = \"outputs/matryoshka_3/\"\n",
    "\n",
    "if not os.path.exists(output_destination):\n",
    "    os.makedirs(output_destination)\n",
    "    \n",
    "with open('dataset/ImageSets/val.txt', 'r') as file:\n",
    "    # Read the lines into a list\n",
    "    filenames = file.read().splitlines()\n",
    "\n",
    "for filename in tqdm(filenames):\n",
    "\n",
    "    args = TestArgs(filename)\n",
    "\n",
    "    pc = read_points(args.pc_path)\n",
    "    pc = point_range_filter(pc)\n",
    "    pc_torch = torch.from_numpy(pc)\n",
    "\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        if not args.no_cuda:\n",
    "            pc_torch = pc_torch.cuda()\n",
    "        \n",
    "        result_filter0, result_filter1, result_filter2 = model(batched_pts=[pc_torch], \n",
    "                                mode='test')\n",
    "        results = [result_filter0, result_filter1, result_filter2]\n",
    "\n",
    "    for model_no in range(3):\n",
    "        result_filter = results[model_no][0]\n",
    "\n",
    "        img = cv2.imread(args.img_path, 1)\n",
    "        gt_label = read_label(args.gt_path)\n",
    "        calib_info = read_calib(args.calib_path)\n",
    "\n",
    "        tr_velo_to_cam = calib_info['Tr_velo_to_cam'].astype(np.float32)\n",
    "        r0_rect = calib_info['R0_rect'].astype(np.float32)\n",
    "        P2 = calib_info['P2'].astype(np.float32)\n",
    "\n",
    "        image_shape = img.shape[:2]\n",
    "        result_filter = keep_bbox_from_image_range(result_filter, tr_velo_to_cam, r0_rect, P2, image_shape)\n",
    "\n",
    "        result_filter = keep_bbox_from_lidar_range(result_filter, pcd_limit_range)\n",
    "        lidar_bboxes = result_filter['lidar_bboxes']\n",
    "        labels, scores = result_filter['labels'], result_filter['scores']\n",
    "\n",
    "        # vis_pc(pc, bboxes=lidar_bboxes, labels=labels)\n",
    "\n",
    "        bboxes2d, camera_bboxes = result_filter['bboxes2d'], result_filter['camera_bboxes'] \n",
    "        bboxes_corners = bbox3d2corners_camera(camera_bboxes)\n",
    "        image_points = points_camera2image(bboxes_corners, P2)\n",
    "        img = vis_img_3d(img, image_points, labels, rt=True)\n",
    "\n",
    "        tr_velo_to_cam = calib_info['Tr_velo_to_cam'].astype(np.float32)\n",
    "        r0_rect = calib_info['R0_rect'].astype(np.float32)\n",
    "\n",
    "        dimensions = gt_label['dimensions']\n",
    "        location = gt_label['location']\n",
    "        rotation_y = gt_label['rotation_y']\n",
    "        gt_labels = np.array([CLASSES.get(item, -1) for item in gt_label['name']])\n",
    "        sel = gt_labels != -1\n",
    "        gt_labels = gt_labels[sel]\n",
    "        bboxes_camera = np.concatenate([location, dimensions, rotation_y[:, None]], axis=-1)\n",
    "        gt_lidar_bboxes = bbox_camera2lidar(bboxes_camera, tr_velo_to_cam, r0_rect)\n",
    "        bboxes_camera = bboxes_camera[sel]\n",
    "        gt_lidar_bboxes = gt_lidar_bboxes[sel]\n",
    "\n",
    "        gt_labels = [-1] * len(gt_label['name']) # to distinguish between the ground truth and the predictions\n",
    "        \n",
    "        pred_gt_lidar_bboxes = np.concatenate([lidar_bboxes, gt_lidar_bboxes], axis=0)\n",
    "        pred_gt_labels = np.concatenate([labels, gt_labels])\n",
    "        # vis_pc(pc, pred_gt_lidar_bboxes, labels=pred_gt_labels)\n",
    "\n",
    "        bboxes_corners = bbox3d2corners_camera(bboxes_camera)\n",
    "        image_points = points_camera2image(bboxes_corners, P2)\n",
    "        gt_labels = [-1] * len(gt_label['name'])\n",
    "        img = vis_img_3d(img, image_points, gt_labels, rt=True)\n",
    "\n",
    "        cv2.imwrite(output_destination + \"det\" + str(model_no)+ \"_\" + filename + \".png\", img)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_destination = \"outputs/matryoshka_merge/\"\n",
    "\n",
    "if not os.path.exists(output_destination):\n",
    "    os.makedirs(output_destination)\n",
    "    \n",
    "with open('dataset/ImageSets/val.txt', 'r') as file:\n",
    "    # Read the lines into a list\n",
    "    filenames = file.read().splitlines()\n",
    "\n",
    "for filename in tqdm(filenames):\n",
    "    im0 = cv2.imread(\"outputs/matryoshka_3/det0_\"+ filename+ \".png\")\n",
    "    im1 = cv2.imread(\"outputs/matryoshka_3/det1_\"+ filename+ \".png\")\n",
    "    im2 = cv2.imread(\"outputs/matryoshka_3/det2_\"+ filename+ \".png\")\n",
    "\n",
    "    im = cv2.vconcat([im0, im1, im2])\n",
    "    cv2.imwrite(output_destination + filename + \".png\", im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file\n",
    "\n",
    "output_destination = \"outputs/matryoshka_energy/\"\n",
    "\n",
    "if not os.path.exists(output_destination):\n",
    "    os.makedirs(output_destination)\n",
    "    \n",
    "with open('dataset/ImageSets/val.txt', 'r') as file:\n",
    "    # Read the lines into a list\n",
    "    filenames = file.read().splitlines()\n",
    "\n",
    "i = 0\n",
    "for filename in tqdm(filenames):\n",
    "\n",
    "    i = i+1\n",
    "    args = TestArgs(filename)\n",
    "\n",
    "    pc = read_points(args.pc_path)\n",
    "    pc = point_range_filter(pc)\n",
    "    pc_torch = torch.from_numpy(pc)\n",
    "\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        if not args.no_cuda:\n",
    "            pc_torch = pc_torch.cuda()\n",
    "        \n",
    "        result_filter0, result_filter1, result_filter2, features = model(batched_pts=[pc_torch], \n",
    "                                mode='test')\n",
    "        # results = [result_filter0, result_filter1, result_filter2]\n",
    "        features_np = np.squeeze(features.detach().cpu().numpy())\n",
    "\n",
    "        features_power = np.linalg.norm(features_np, ord=2, axis=(1,2))\n",
    "\n",
    "        plt.plot(features_power)\n",
    "\n",
    "    \n",
    "        # cv2.imwrite(output_destination + \"det\" + str(model_no)+ \"_\" + filename + \".png\", img)\n",
    "\n",
    "    if i==20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features_np = np.squeeze(features.detach().cpu().numpy())\n",
    "\n",
    "features_power = np.linalg.norm(features_np, ord=2, axis=(1,2))\n",
    "\n",
    "plt.plot(features_power)\n",
    "# for i in range(64):\n",
    "#     plt.imshow(features_np[i, :, :])\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
